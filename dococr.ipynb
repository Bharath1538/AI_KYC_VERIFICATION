{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc36e4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1267914315.py, line 34)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"Successfully downloaded inference.py\")\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import cv2\n",
    "# import fileinput\n",
    "# from huggingface_hub import hf_hub_download\n",
    "\n",
    "# print(\"\\nDeploying inference script...\")\n",
    "# try:\n",
    "#     inference_path = hf_hub_download(\n",
    "#         repo_id=\"logasanjeev/indian-id-validator\",\n",
    "#         filename=\"inference.py\"\n",
    "#     )\n",
    "#     shutil.copy2(inference_path, \"inference.py\")\n",
    "    \n",
    "#     # for line in fileinput.input(\"inference.py\", inplace=True):\n",
    "#     #     line = line.replace(\"show_log=False\", \"\")\n",
    "#     #     line = line.replace(\", cls=True\", \"\")\n",
    "#     #     line = line.replace(\"cls=True, \", \"\")\n",
    "#     #     line = line.replace(\"cls=True\", \"\")\n",
    "#     #     print(line, end=\"\")\n",
    "\n",
    "#     print(\"Successfully downloaded inference.py\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error downloading inference.py: {e}\")\n",
    "#     print(\"Please verify that inference.py exists at https://huggingface.co/logasanjeev/indian-id-validator\")\n",
    "#     raise\n",
    "\n",
    "# print(\"\\nLoading inference functions...\")\n",
    "# try:\n",
    "#     from inference import process_id\n",
    "#     print(\"Successfully imported inference functions\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error importing inference functions: {e}\")\n",
    "#     raise\n",
    "\n",
    "# # Clarity check function using Laplacian variance\n",
    "# def is_image_clear(img, blur_threshold=100.0):\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     variance = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "#     return variance > blur_threshold\n",
    "\n",
    "# def infer_document(image_path: str):\n",
    "#     img = cv2.imread(image_path)\n",
    "#     if img is None:\n",
    "#         return {\"status\": \"error\", \"error\": \"Image file not found.\"}\n",
    "\n",
    "#     # Check image clarity before inference\n",
    "#     if not is_image_clear(img):\n",
    "#         return {\"status\": \"error\", \"error\": \"Image too blurry or low-quality. Please upload a clearer photo.\"}\n",
    "\n",
    "#     # Run classification + extraction via official pipeline\n",
    "#     result = process_id(image_path)\n",
    "\n",
    "#     # Add a fallback for unclear classification or unsupported docs\n",
    "#     if \"status\" in result and result[\"status\"] == \"error\":\n",
    "#         return result\n",
    "\n",
    "#     return result\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     # Example with a sample image (downloaded or your own)\n",
    "# #     test_image = r\"C:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\aadhar2.jpg\"  # replace with your test image path\n",
    "# #     output = infer_document(test_image)\n",
    "# #     print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c0611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deploying inference script...\n",
      "âœ… Successfully downloaded and patched inference.py\n",
      "\n",
      "Loading inference functions...\n",
      "Successfully imported inference functions\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import cv2\n",
    "# from huggingface_hub import hf_hub_download\n",
    "\n",
    "# print(\"\\nDeploying inference script...\")\n",
    "# try:\n",
    "#     inference_path = hf_hub_download(\n",
    "#         repo_id=\"logasanjeev/indian-id-validator\",\n",
    "#         filename=\"inference.py\"\n",
    "#     )\n",
    "#     shutil.copy2(inference_path, \"inference.py\")\n",
    "\n",
    "#     # ðŸ”§ Patch inference.py to remove cls= (since paddleocr>=3.x doesnâ€™t support it)\n",
    "#     patched_lines = []\n",
    "#     with open(\"inference.py\", \"r\", encoding=\"utf-8\") as f:\n",
    "#         for line in f:\n",
    "#             # Remove all cls=True/False params from PaddleOCR calls\n",
    "#             line = line.replace(\"cls=True\", \"\").replace(\"cls=False\", \"\")\n",
    "#             # Clean trailing commas after removal\n",
    "#             line = line.replace(\", )\", \")\").replace(\"(,\", \"(\")\n",
    "#             patched_lines.append(line)\n",
    "\n",
    "#     with open(\"inference.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.writelines(patched_lines)\n",
    "\n",
    "\n",
    "#     print(\"âœ… Successfully downloaded and patched inference.py\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error downloading inference.py: {e}\")\n",
    "#     print(\"Please verify that inference.py exists at https://huggingface.co/logasanjeev/indian-id-validator\")\n",
    "#     raise\n",
    "\n",
    "# print(\"\\nLoading inference functions...\")\n",
    "# try:\n",
    "#     from inference import process_id\n",
    "#     print(\"Successfully imported inference functions\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error importing inference functions: {e}\")\n",
    "#     raise\n",
    "\n",
    "\n",
    "# # Clarity check function using Laplacian variance\n",
    "# def is_image_clear(img, blur_threshold=100.0):\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     variance = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "#     return variance > blur_threshold\n",
    "\n",
    "\n",
    "# def infer_document(image_path: str):\n",
    "#     img = cv2.imread(image_path)\n",
    "#     if img is None:\n",
    "#         return {\"status\": \"error\", \"error\": \"Image file not found.\"}\n",
    "\n",
    "#     # Check image clarity before inference\n",
    "#     if not is_image_clear(img):\n",
    "#         return {\"status\": \"error\", \"error\": \"Image too blurry or low-quality. Please upload a clearer photo.\"}\n",
    "\n",
    "#     # Run classification + extraction via official pipeline\n",
    "#     result = process_id(image_path)\n",
    "\n",
    "#     # Add a fallback for unclear classification or unsupported docs\n",
    "#     if \"status\" in result and result[\"status\"] == \"error\":\n",
    "#         return result\n",
    "\n",
    "#     return result\n",
    "\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     test_image = r\"C:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\aadhar2.jpg\"\n",
    "# #     output = infer_document(test_image)\n",
    "# #     print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdeb8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected document type: aadhar_front with confidence: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:inference:Error processing class Name: PaddleOCR.predict() got an unexpected keyword argument 'cls'\n",
      "ERROR:inference:Error processing class Aadhaar: PaddleOCR.predict() got an unexpected keyword argument 'cls'\n",
      "ERROR:inference:Error processing class DOB: PaddleOCR.predict() got an unexpected keyword argument 'cls'\n",
      "ERROR:inference:Error processing class Gender: PaddleOCR.predict() got an unexpected keyword argument 'cls'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Example with a sample image (downloaded or your own)\n",
    "#     test_image = r\"C:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\aadhar2.jpg\"  # replace with your test image path\n",
    "#     output = infer_document(test_image)\n",
    "#     print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53da0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\siva_\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'paddle.base.libpaddle.AnalysisConfig' object has no attribute 'set_optimization_level'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minference\u001b[39;00m\n\u001b[32m      2\u001b[39m result = inference.process_id(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33msiva_\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDesktop\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mPROJECTS\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mCAPSTONE-AIDETECT\u001b[39m\u001b[33m\\\u001b[39m\u001b[33maadhar2.jpg\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\inference.py:27\u001b[39m\n\u001b[32m     24\u001b[39m CONFIG = load_config()\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Initialize PaddleOCR\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m OCR = \u001b[43mPaddleOCR\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_angle_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43men\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Preprocessing functions\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupscale_image\u001b[39m(image, scale=\u001b[32m2\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\ocr.py:163\u001b[39m, in \u001b[36mPaddleOCR.__init__\u001b[39m\u001b[34m(self, doc_orientation_classify_model_name, doc_orientation_classify_model_dir, doc_unwarping_model_name, doc_unwarping_model_dir, text_detection_model_name, text_detection_model_dir, textline_orientation_model_name, textline_orientation_model_dir, textline_orientation_batch_size, text_recognition_model_name, text_recognition_model_dir, text_recognition_batch_size, use_doc_orientation_classify, use_doc_unwarping, use_textline_orientation, text_det_limit_side_len, text_det_limit_type, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, text_det_input_shape, text_rec_score_thresh, return_word_box, text_rec_input_shape, lang, ocr_version, **kwargs)\u001b[39m\n\u001b[32m    159\u001b[39m         base_params[name] = val\n\u001b[32m    161\u001b[39m \u001b[38;5;28mself\u001b[39m._params = params\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbase_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\base.py:67\u001b[39m, in \u001b[36mPaddleXPipelineWrapper.__init__\u001b[39m\u001b[34m(self, paddlex_config, **common_args)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m._common_args = parse_common_args(\n\u001b[32m     64\u001b[39m     common_args, default_enable_hpi=_DEFAULT_ENABLE_HPI\n\u001b[32m     65\u001b[39m )\n\u001b[32m     66\u001b[39m \u001b[38;5;28mself\u001b[39m._merged_paddlex_config = \u001b[38;5;28mself\u001b[39m._get_merged_paddlex_config()\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28mself\u001b[39m.paddlex_pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_paddlex_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\base.py:102\u001b[39m, in \u001b[36mPaddleXPipelineWrapper._create_paddlex_pipeline\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    100\u001b[39m kwargs = prepare_common_init_args(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m._common_args)\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merged_paddlex_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m DependencyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    105\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA dependency error occurred during pipeline creation. Please refer to the installation documentation to ensure all required dependencies are installed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    106\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\__init__.py:166\u001b[39m, in \u001b[36mcreate_pipeline\u001b[39m\u001b[34m(pipeline, config, device, pp_option, use_hpip, hpi_config, *args, **kwargs)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    164\u001b[39m     config.pop(\u001b[33m\"\u001b[39m\u001b[33mhpi_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m pipeline = \u001b[43mBasePipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\utils\\deps.py:202\u001b[39m, in \u001b[36mpipeline_requires_extra.<locals>._deco.<locals>._wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(pipeline_cls.\u001b[34m__init__\u001b[39m)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    201\u001b[39m     require_extra(extra, obj_name=pipeline_name, alt=alt)\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_init_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:103\u001b[39m, in \u001b[36mAutoParallelSimpleInferencePipeline.__init__\u001b[39m\u001b[34m(self, config, *args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m         \u001b[38;5;28mself\u001b[39m._executor = MultiDeviceSimpleInferenceExecutor(\n\u001b[32m     98\u001b[39m             \u001b[38;5;28mself\u001b[39m._pipelines,\n\u001b[32m     99\u001b[39m             batch_sampler,\n\u001b[32m    100\u001b[39m             postprocess_result=\u001b[38;5;28mself\u001b[39m._postprocess_result,\n\u001b[32m    101\u001b[39m         )\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._multi_device_inference:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28mself\u001b[39m._pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_internal_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:158\u001b[39m, in \u001b[36mAutoParallelImageSimpleInferencePipeline._create_internal_pipeline\u001b[39m\u001b[34m(self, config, device)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_internal_pipeline\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, device):\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipeline_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\ocr\\pipeline.py:76\u001b[39m, in \u001b[36m_OCRPipeline.__init__\u001b[39m\u001b[34m(self, config, device, pp_option, use_hpip, hpi_config)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_doc_preprocessor:\n\u001b[32m     70\u001b[39m     doc_preprocessor_config = config.get(\u001b[33m\"\u001b[39m\u001b[33mSubPipelines\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDocPreprocessor\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     72\u001b[39m         {\n\u001b[32m     73\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpipeline_config_error\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mconfig error for doc_preprocessor_pipeline!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         },\n\u001b[32m     75\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28mself\u001b[39m.doc_preprocessor_pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdoc_preprocessor_config\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28mself\u001b[39m.use_textline_orientation = config.get(\u001b[33m\"\u001b[39m\u001b[33muse_textline_orientation\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_textline_orientation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\base.py:138\u001b[39m, in \u001b[36mBasePipeline.create_pipeline\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m    135\u001b[39m     hpi_config = hpi_config \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    136\u001b[39m     hpi_config = {**\u001b[38;5;28mself\u001b[39m.hpi_config, **hpi_config}\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m pipeline = \u001b[43mcreate_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpp_option\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\__init__.py:166\u001b[39m, in \u001b[36mcreate_pipeline\u001b[39m\u001b[34m(pipeline, config, device, pp_option, use_hpip, hpi_config, *args, **kwargs)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    164\u001b[39m     config.pop(\u001b[33m\"\u001b[39m\u001b[33mhpi_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m pipeline = \u001b[43mBasePipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\utils\\deps.py:202\u001b[39m, in \u001b[36mpipeline_requires_extra.<locals>._deco.<locals>._wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(pipeline_cls.\u001b[34m__init__\u001b[39m)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    201\u001b[39m     require_extra(extra, obj_name=pipeline_name, alt=alt)\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_init_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:103\u001b[39m, in \u001b[36mAutoParallelSimpleInferencePipeline.__init__\u001b[39m\u001b[34m(self, config, *args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m         \u001b[38;5;28mself\u001b[39m._executor = MultiDeviceSimpleInferenceExecutor(\n\u001b[32m     98\u001b[39m             \u001b[38;5;28mself\u001b[39m._pipelines,\n\u001b[32m     99\u001b[39m             batch_sampler,\n\u001b[32m    100\u001b[39m             postprocess_result=\u001b[38;5;28mself\u001b[39m._postprocess_result,\n\u001b[32m    101\u001b[39m         )\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._multi_device_inference:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28mself\u001b[39m._pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_internal_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:158\u001b[39m, in \u001b[36mAutoParallelImageSimpleInferencePipeline._create_internal_pipeline\u001b[39m\u001b[34m(self, config, device)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_internal_pipeline\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, device):\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipeline_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\doc_preprocessor\\pipeline.py:69\u001b[39m, in \u001b[36m_DocPreprocessorPipeline.__init__\u001b[39m\u001b[34m(self, config, device, pp_option, use_hpip, hpi_config)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_doc_orientation_classify:\n\u001b[32m     65\u001b[39m     doc_ori_classify_config = config.get(\u001b[33m\"\u001b[39m\u001b[33mSubModules\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDocOrientationClassify\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mmodel_config_error\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mconfig error for doc_ori_classify_model!\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     68\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28mself\u001b[39m.doc_ori_classify_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_ori_classify_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mself\u001b[39m.use_doc_unwarping = config.get(\u001b[33m\"\u001b[39m\u001b[33muse_doc_unwarping\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_doc_unwarping:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\base.py:105\u001b[39m, in \u001b[36mBasePipeline.create_model\u001b[39m\u001b[34m(self, config, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    103\u001b[39m     pp_option = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m model = \u001b[43mcreate_predictor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\models\\__init__.py:77\u001b[39m, in \u001b[36mcreate_predictor\u001b[39m\u001b[34m(model_name, model_dir, device, pp_option, use_hpip, hpi_config, *args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m config = BasePredictor.load_config(model_dir)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m     75\u001b[39m     model_name == config[\u001b[33m\"\u001b[39m\u001b[33mGlobal\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     76\u001b[39m ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel name mismatchï¼Œplease input the correct model dir.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBasePredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\models\\image_classification\\predictor.py:49\u001b[39m, in \u001b[36mClasPredictor.__init__\u001b[39m\u001b[34m(self, topk, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(*args, **kwargs)\n\u001b[32m     48\u001b[39m \u001b[38;5;28mself\u001b[39m.topk = topk\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28mself\u001b[39m.preprocessors, \u001b[38;5;28mself\u001b[39m.infer, \u001b[38;5;28mself\u001b[39m.postprocessors = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\models\\image_classification\\predictor.py:82\u001b[39m, in \u001b[36mClasPredictor._build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m     preprocessors[name] = op\n\u001b[32m     80\u001b[39m preprocessors[\u001b[33m\"\u001b[39m\u001b[33mToBatch\u001b[39m\u001b[33m\"\u001b[39m] = ToBatch()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m infer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_static_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m postprocessors = {}\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mPostProcess\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\models\\base\\predictor\\base_predictor.py:248\u001b[39m, in \u001b[36mBasePredictor.create_static_infer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_static_infer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_hpip:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPaddleInfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mMODEL_FILE_PREFIX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pp_option\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    252\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m HPInfer(\n\u001b[32m    253\u001b[39m             \u001b[38;5;28mself\u001b[39m.model_dir,\n\u001b[32m    254\u001b[39m             \u001b[38;5;28mself\u001b[39m.MODEL_FILE_PREFIX,\n\u001b[32m    255\u001b[39m             \u001b[38;5;28mself\u001b[39m._hpi_config,\n\u001b[32m    256\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\models\\common\\static_infer.py:284\u001b[39m, in \u001b[36mPaddleInfer.__init__\u001b[39m\u001b[34m(self, model_name, model_dir, model_file_prefix, option)\u001b[39m\n\u001b[32m    282\u001b[39m \u001b[38;5;28mself\u001b[39m.model_file_prefix = model_file_prefix\n\u001b[32m    283\u001b[39m \u001b[38;5;28mself\u001b[39m._option = option\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m \u001b[38;5;28mself\u001b[39m.predictor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[38;5;28mself\u001b[39m.infer = PaddleInferChainLegacy(\u001b[38;5;28mself\u001b[39m.predictor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\models\\common\\static_infer.py:465\u001b[39m, in \u001b[36mPaddleInfer._create\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    463\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33menable_new_executor\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    464\u001b[39m             config.enable_new_executor()\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m         \u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_optimization_level\u001b[49m(\u001b[32m3\u001b[39m)\n\u001b[32m    467\u001b[39m config.enable_memory_optim()\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m del_p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._option.delete_pass:\n",
      "\u001b[31mAttributeError\u001b[39m: 'paddle.base.libpaddle.AnalysisConfig' object has no attribute 'set_optimization_level'"
     ]
    }
   ],
   "source": [
    "# import inference\n",
    "# result = inference.process_id(r\"C:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\aadhar2.jpg\")\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681c0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.1\n"
     ]
    }
   ],
   "source": [
    "# import paddle\n",
    "# print(paddle.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f815e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement paddlepaddle==2.4.2 (from versions: 2.6.0, 2.6.1, 2.6.2, 3.0.0b0, 3.0.0b1, 3.0.0b2, 3.0.0rc0, 3.0.0rc1, 3.0.0, 3.1.0, 3.1.1, 3.2.0)\n",
      "ERROR: No matching distribution found for paddlepaddle==2.4.2\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install paddlepaddle==2.4.2 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf36f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cls= arguments found. Good to go.\n"
     ]
    }
   ],
   "source": [
    "# with open(r\"c:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\inference.py\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     content = f.read()\n",
    "# assert \"cls=\" not in content, \"Found obsolete 'cls=' argument in inference.py!\"\n",
    "# print(\"No cls= arguments found. Good to go.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f09e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=r\"C:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\aadhar3.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f0dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openbharatocr \n",
    "# import pytesseract\n",
    "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "# # Extract PAN card details\n",
    "# # import openbharatocr \n",
    "\n",
    "# # Front side\n",
    "# front_result = openbharatocr.front_aadhaar(image_path)\n",
    "# # Returns: {'name': str, 'dob': str, 'gender': str, 'aadhaar_number': str}\n",
    "\n",
    "# # Back side\n",
    "# back_result = openbharatocr.back_aadhaar(image_path)\n",
    "# # Returns: {'address': str, 'aadhaar_number': str, 'pin_code': str}\n",
    "# # Returns: {'name': str, 'father_name': str, 'dob': str, 'pan_number': str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bcf30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Full Name': 'Goseinmentcflnta', 'Date/Year of Birth': '01/91/1991', 'Gender': 'Male', 'Aadhaar Number': '6754 3973 8680'}\n"
     ]
    }
   ],
   "source": [
    "# print(front_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce752ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ota Hid\n",
      "Ranajit Mondal\n",
      "\n",
      "gen arire/D0B 95/12/1993\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import pytesseract\n",
    "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# from PIL import Image\n",
    "\n",
    "# # Test it\n",
    "# print(pytesseract.image_to_string(Image.open(image_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591a75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Name\": \"\",\n",
      "    \"DOB\": \"\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Aadhaar Number\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# from edgeidx.ocr import extract_aadhaar_details\n",
    "\n",
    "# print(extract_aadhaar_details(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6c978e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: surya-ocr in c:\\users\\siva_\\anaconda3\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.8 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (8.3.0)\n",
      "Requirement already satisfied: einops<0.9.0,>=0.8.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (0.8.1)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (1.2.0)\n",
      "Requirement already satisfied: opencv-python-headless==4.11.0.86 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (4.11.0.86)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.2.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (10.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.6 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (4.5.0)\n",
      "Requirement already satisfied: pre-commit<5.0.0,>=4.2.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (4.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (2.11.3)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.1.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (2.9.1)\n",
      "Requirement already satisfied: pypdfium2==4.30.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (4.30.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (1.1.0)\n",
      "Collecting torch<3.0.0,>=2.7.0 (from surya-ocr)\n",
      "  Using cached torch-2.9.0-cp311-cp311-win_amd64.whl (109.3 MB)\n",
      "Requirement already satisfied: transformers>=4.56.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (4.57.1)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from opencv-python-headless==4.11.0.86->surya-ocr) (1.26.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from click<9.0.0,>=8.1.8->surya-ocr) (0.4.6)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (2.6.15)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (1.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (6.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (20.26.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.3->surya-ocr) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.3->surya-ocr) (2.33.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.3->surya-ocr) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.3->surya-ocr) (0.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.7.0->surya-ocr) (3.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.7.0->surya-ocr) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.7.0->surya-ocr) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.7.0->surya-ocr) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.7.0->surya-ocr) (2025.3.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (2.29.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (4.65.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch<3.0.0,>=2.7.0->surya-ocr) (1.2.1)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit<5.0.0,>=4.2.0->surya-ocr) (0.3.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from jinja2->torch<3.0.0,>=2.7.0->surya-ocr) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers>=4.56.1->surya-ocr) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers>=4.56.1->surya-ocr) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers>=4.56.1->surya-ocr) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers>=4.56.1->surya-ocr) (2025.10.5)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "Successfully installed torch-2.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lmdeploy 0.7.2.post1 requires torch<=2.5.1,>=2.0.0, but you have torch 2.9.0 which is incompatible.\n",
      "torchaudio 2.5.1 requires torch==2.5.1, but you have torch 2.9.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install surya-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d472cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseractNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pytesseract) (10.4.0)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775636e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: surya-ocrNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 0.17.0\n",
      "Summary: OCR, layout, reading order, and table recognition in 90+ languages\n",
      "Home-page: \n",
      "Author: Vik Paruchuri\n",
      "Author-email: vik.paruchuri@gmail.com\n",
      "License: GPL-3.0-or-later\n",
      "Location: c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\n",
      "Requires: click, einops, filetype, opencv-python-headless, pillow, platformdirs, pre-commit, pydantic, pydantic-settings, pypdfium2, python-dotenv, torch, transformers\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "pip show surya-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddebc280",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surya.ocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Install Surya first (if not installed):\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# pip install surya-ocr\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mocr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_ocr\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_image\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surya.ocr'"
     ]
    }
   ],
   "source": [
    "# Install Surya first (if not installed):\n",
    "# pip install surya-ocr\n",
    "\n",
    "from surya.ocr import run_ocr\n",
    "from surya.utils import load_image\n",
    "import re\n",
    "\n",
    "# Load your ID image\n",
    "# image_path = \"sample_pan.jpg\"   # or Aadhaar, Passport, DL\n",
    "image = load_image(image_path)\n",
    "\n",
    "# Run Surya OCR (built-in model)\n",
    "ocr_result = run_ocr([image])\n",
    "\n",
    "# Combine all recognized text into one string\n",
    "text = \" \".join([line[\"text\"] for block in ocr_result for line in block[\"lines\"]])\n",
    "print(\"Extracted Text:\\n\", text)\n",
    "\n",
    "# ---------- Regex Extractors ----------\n",
    "# Aadhaar Number (12 digits, may be split in 4-4-4 format)\n",
    "aadhaar_match = re.search(r\"\\b\\d{4}\\s?\\d{4}\\s?\\d{4}\\b\", text)\n",
    "\n",
    "# PAN Number (5 letters, 4 digits, 1 letter)\n",
    "pan_match = re.search(r\"\\b[A-Z]{5}[0-9]{4}[A-Z]\\b\", text)\n",
    "\n",
    "# Date of Birth (DD/MM/YYYY or similar)\n",
    "dob_match = re.search(r\"\\b\\d{2}[/-]\\d{2}[/-]\\d{4}\\b\", text)\n",
    "\n",
    "print(\"\\nExtracted Fields:\")\n",
    "print(\"Aadhaar:\", aadhaar_match.group(0) if aadhaar_match else \"Not found\")\n",
    "print(\"PAN:\", pan_match.group(0) if pan_match else \"Not found\")\n",
    "print(\"DOB:\", dob_match.group(0) if dob_match else \"Not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b7fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\siva_\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'paddle.base.libpaddle.AnalysisConfig' object has no attribute 'set_optimization_level'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Initialize PaddleOCR with Hindi support\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m ocr = \u001b[43mPaddleOCR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhi\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or 'en' for English\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Extract text from cropped regions\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_aadhaar_details\u001b[39m(image_path):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\ocr.py:163\u001b[39m, in \u001b[36mPaddleOCR.__init__\u001b[39m\u001b[34m(self, doc_orientation_classify_model_name, doc_orientation_classify_model_dir, doc_unwarping_model_name, doc_unwarping_model_dir, text_detection_model_name, text_detection_model_dir, textline_orientation_model_name, textline_orientation_model_dir, textline_orientation_batch_size, text_recognition_model_name, text_recognition_model_dir, text_recognition_batch_size, use_doc_orientation_classify, use_doc_unwarping, use_textline_orientation, text_det_limit_side_len, text_det_limit_type, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, text_det_input_shape, text_rec_score_thresh, return_word_box, text_rec_input_shape, lang, ocr_version, **kwargs)\u001b[39m\n\u001b[32m    159\u001b[39m         base_params[name] = val\n\u001b[32m    161\u001b[39m \u001b[38;5;28mself\u001b[39m._params = params\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbase_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\base.py:67\u001b[39m, in \u001b[36mPaddleXPipelineWrapper.__init__\u001b[39m\u001b[34m(self, paddlex_config, **common_args)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m._common_args = parse_common_args(\n\u001b[32m     64\u001b[39m     common_args, default_enable_hpi=_DEFAULT_ENABLE_HPI\n\u001b[32m     65\u001b[39m )\n\u001b[32m     66\u001b[39m \u001b[38;5;28mself\u001b[39m._merged_paddlex_config = \u001b[38;5;28mself\u001b[39m._get_merged_paddlex_config()\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28mself\u001b[39m.paddlex_pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_paddlex_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\base.py:102\u001b[39m, in \u001b[36mPaddleXPipelineWrapper._create_paddlex_pipeline\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    100\u001b[39m kwargs = prepare_common_init_args(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m._common_args)\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merged_paddlex_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m DependencyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    105\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA dependency error occurred during pipeline creation. Please refer to the installation documentation to ensure all required dependencies are installed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    106\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\__init__.py:166\u001b[39m, in \u001b[36mcreate_pipeline\u001b[39m\u001b[34m(pipeline, config, device, pp_option, use_hpip, hpi_config, *args, **kwargs)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    164\u001b[39m     config.pop(\u001b[33m\"\u001b[39m\u001b[33mhpi_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m pipeline = \u001b[43mBasePipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\utils\\deps.py:202\u001b[39m, in \u001b[36mpipeline_requires_extra.<locals>._deco.<locals>._wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(pipeline_cls.\u001b[34m__init__\u001b[39m)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    201\u001b[39m     require_extra(extra, obj_name=pipeline_name, alt=alt)\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_init_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:103\u001b[39m, in \u001b[36mAutoParallelSimpleInferencePipeline.__init__\u001b[39m\u001b[34m(self, config, *args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m         \u001b[38;5;28mself\u001b[39m._executor = MultiDeviceSimpleInferenceExecutor(\n\u001b[32m     98\u001b[39m             \u001b[38;5;28mself\u001b[39m._pipelines,\n\u001b[32m     99\u001b[39m             batch_sampler,\n\u001b[32m    100\u001b[39m             postprocess_result=\u001b[38;5;28mself\u001b[39m._postprocess_result,\n\u001b[32m    101\u001b[39m         )\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._multi_device_inference:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28mself\u001b[39m._pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_internal_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:158\u001b[39m, in \u001b[36mAutoParallelImageSimpleInferencePipeline._create_internal_pipeline\u001b[39m\u001b[34m(self, config, device)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_internal_pipeline\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, device):\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipeline_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\ocr\\pipeline.py:76\u001b[39m, in \u001b[36m_OCRPipeline.__init__\u001b[39m\u001b[34m(self, config, device, pp_option, use_hpip, hpi_config)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_doc_preprocessor:\n\u001b[32m     70\u001b[39m     doc_preprocessor_config = config.get(\u001b[33m\"\u001b[39m\u001b[33mSubPipelines\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDocPreprocessor\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     72\u001b[39m         {\n\u001b[32m     73\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpipeline_config_error\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mconfig error for doc_preprocessor_pipeline!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         },\n\u001b[32m     75\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28mself\u001b[39m.doc_preprocessor_pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdoc_preprocessor_config\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28mself\u001b[39m.use_textline_orientation = config.get(\u001b[33m\"\u001b[39m\u001b[33muse_textline_orientation\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_textline_orientation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\base.py:138\u001b[39m, in \u001b[36mBasePipeline.create_pipeline\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m    135\u001b[39m     hpi_config = hpi_config \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    136\u001b[39m     hpi_config = {**\u001b[38;5;28mself\u001b[39m.hpi_config, **hpi_config}\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m pipeline = \u001b[43mcreate_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpp_option\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\__init__.py:166\u001b[39m, in \u001b[36mcreate_pipeline\u001b[39m\u001b[34m(pipeline, config, device, pp_option, use_hpip, hpi_config, *args, **kwargs)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    164\u001b[39m     config.pop(\u001b[33m\"\u001b[39m\u001b[33mhpi_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m pipeline = \u001b[43mBasePipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\utils\\deps.py:202\u001b[39m, in \u001b[36mpipeline_requires_extra.<locals>._deco.<locals>._wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(pipeline_cls.\u001b[34m__init__\u001b[39m)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    201\u001b[39m     require_extra(extra, obj_name=pipeline_name, alt=alt)\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_init_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:103\u001b[39m, in \u001b[36mAutoParallelSimpleInferencePipeline.__init__\u001b[39m\u001b[34m(self, config, *args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m         \u001b[38;5;28mself\u001b[39m._executor = MultiDeviceSimpleInferenceExecutor(\n\u001b[32m     98\u001b[39m             \u001b[38;5;28mself\u001b[39m._pipelines,\n\u001b[32m     99\u001b[39m             batch_sampler,\n\u001b[32m    100\u001b[39m             postprocess_result=\u001b[38;5;28mself\u001b[39m._postprocess_result,\n\u001b[32m    101\u001b[39m         )\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._multi_device_inference:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28mself\u001b[39m._pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_internal_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:158\u001b[39m, in \u001b[36mAutoParallelImageSimpleInferencePipeline._create_internal_pipeline\u001b[39m\u001b[34m(self, config, device)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_internal_pipeline\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, device):\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipeline_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\doc_preprocessor\\pipeline.py:69\u001b[39m, in \u001b[36m_DocPreprocessorPipeline.__init__\u001b[39m\u001b[34m(self, config, device, pp_option, use_hpip, hpi_config)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_doc_orientation_classify:\n\u001b[32m     65\u001b[39m     doc_ori_classify_config = config.get(\u001b[33m\"\u001b[39m\u001b[33mSubModules\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDocOrientationClassify\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mmodel_config_error\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mconfig error for doc_ori_classify_model!\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     68\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28mself\u001b[39m.doc_ori_classify_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_ori_classify_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mself\u001b[39m.use_doc_unwarping = config.get(\u001b[33m\"\u001b[39m\u001b[33muse_doc_unwarping\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_doc_unwarping:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\base.py:105\u001b[39m, in \u001b[36mBasePipeline.create_model\u001b[39m\u001b[34m(self, config, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    103\u001b[39m     pp_option = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m model = \u001b[43mcreate_predictor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\models\\__init__.py:77\u001b[39m, in \u001b[36mcreate_predictor\u001b[39m\u001b[34m(model_name, model_dir, device, pp_option, use_hpip, hpi_config, *args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m config = BasePredictor.load_config(model_dir)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m     75\u001b[39m     model_name == config[\u001b[33m\"\u001b[39m\u001b[33mGlobal\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     76\u001b[39m ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel name mismatchï¼Œplease input the correct model dir.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBasePredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\models\\image_classification\\predictor.py:49\u001b[39m, in \u001b[36mClasPredictor.__init__\u001b[39m\u001b[34m(self, topk, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(*args, **kwargs)\n\u001b[32m     48\u001b[39m \u001b[38;5;28mself\u001b[39m.topk = topk\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28mself\u001b[39m.preprocessors, \u001b[38;5;28mself\u001b[39m.infer, \u001b[38;5;28mself\u001b[39m.postprocessors = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\models\\image_classification\\predictor.py:82\u001b[39m, in \u001b[36mClasPredictor._build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m     preprocessors[name] = op\n\u001b[32m     80\u001b[39m preprocessors[\u001b[33m\"\u001b[39m\u001b[33mToBatch\u001b[39m\u001b[33m\"\u001b[39m] = ToBatch()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m infer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_static_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m postprocessors = {}\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mPostProcess\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\models\\base\\predictor\\base_predictor.py:248\u001b[39m, in \u001b[36mBasePredictor.create_static_infer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_static_infer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_hpip:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPaddleInfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mMODEL_FILE_PREFIX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pp_option\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    252\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m HPInfer(\n\u001b[32m    253\u001b[39m             \u001b[38;5;28mself\u001b[39m.model_dir,\n\u001b[32m    254\u001b[39m             \u001b[38;5;28mself\u001b[39m.MODEL_FILE_PREFIX,\n\u001b[32m    255\u001b[39m             \u001b[38;5;28mself\u001b[39m._hpi_config,\n\u001b[32m    256\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\models\\common\\static_infer.py:284\u001b[39m, in \u001b[36mPaddleInfer.__init__\u001b[39m\u001b[34m(self, model_name, model_dir, model_file_prefix, option)\u001b[39m\n\u001b[32m    282\u001b[39m \u001b[38;5;28mself\u001b[39m.model_file_prefix = model_file_prefix\n\u001b[32m    283\u001b[39m \u001b[38;5;28mself\u001b[39m._option = option\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m \u001b[38;5;28mself\u001b[39m.predictor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[38;5;28mself\u001b[39m.infer = PaddleInferChainLegacy(\u001b[38;5;28mself\u001b[39m.predictor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\models\\common\\static_infer.py:465\u001b[39m, in \u001b[36mPaddleInfer._create\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    463\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33menable_new_executor\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    464\u001b[39m             config.enable_new_executor()\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m         \u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_optimization_level\u001b[49m(\u001b[32m3\u001b[39m)\n\u001b[32m    467\u001b[39m config.enable_memory_optim()\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m del_p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._option.delete_pass:\n",
      "\u001b[31mAttributeError\u001b[39m: 'paddle.base.libpaddle.AnalysisConfig' object has no attribute 'set_optimization_level'"
     ]
    }
   ],
   "source": [
    "# from paddleocr import PaddleOCR\n",
    "# import re\n",
    "\n",
    "# # Initialize PaddleOCR with Hindi support\n",
    "# ocr = PaddleOCR(lang='hi')  # or 'en' for English\n",
    "\n",
    "# # Extract text from cropped regions\n",
    "# def extract_aadhaar_details(image_path):\n",
    "#     result = ocr.ocr(image_path, cls=False)\n",
    "    \n",
    "#     extracted_text = []\n",
    "#     for line in result:\n",
    "#         extracted_text.append(line[58])\n",
    "    \n",
    "#     full_text = ' '.join(extracted_text)\n",
    "    \n",
    "#     # Extract specific fields using regex\n",
    "#     details = {}\n",
    "    \n",
    "#     # Aadhaar Number (12 digits, can be spaced)\n",
    "#     aadhaar_pattern = r'[2-9]\\d{3}\\s?\\d{4}\\s?\\d{4}'\n",
    "#     aadhaar_match = re.search(aadhaar_pattern, full_text)\n",
    "#     details['aadhaar_number'] = aadhaar_match.group() if aadhaar_match else None\n",
    "    \n",
    "#     # Date of Birth (DD/MM/YYYY or DD-MM-YYYY)\n",
    "#     dob_pattern = r'\\d{2}[/-]\\d{2}[/-]\\d{4}'\n",
    "#     dob_match = re.search(dob_pattern, full_text)\n",
    "#     details['dob'] = dob_match.group() if dob_match else None\n",
    "    \n",
    "#     # Gender (Male/Female)\n",
    "#     gender_pattern = r'(?i)(male|female|à¤ªà¥à¤°à¥à¤·|à¤®à¤¹à¤¿à¤²à¤¾)'\n",
    "#     gender_match = re.search(gender_pattern, full_text)\n",
    "#     details['gender'] = gender_match.group() if gender_match else None\n",
    "    \n",
    "#     return details, full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b25a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PP_ChatOCRv4' from 'paddleocr' (c:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpaddleocr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PPStructureV3, PP_ChatOCRv4\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpaddlex\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_pipeline\n\u001b[32m      3\u001b[39m pipeline = create_pipeline(pipeline=\u001b[33m\"\u001b[39m\u001b[33mPP-ChatOCRv4\u001b[39m\u001b[33m\"\u001b[39m, initial_predictor=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'PP_ChatOCRv4' from 'paddleocr' (c:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# from paddleocr import PPStructureV3, PP_ChatOCRv4\n",
    "# from paddlex import create_pipeline\n",
    "# pipeline = create_pipeline(pipeline=\"PP-ChatOCRv4\", initial_predictor=False)\n",
    "\n",
    "# # Initialize with structured extraction\n",
    "# # pipeline = PPStructureV3(\n",
    "# #     use_pdf_structure=True,\n",
    "# #     use_key_info_extraction=True\n",
    "# # )\n",
    "# pipeline = PPStructureV3(\n",
    "#     use_doc_orientation_classify=False,\n",
    "#     use_doc_unwarping=False\n",
    "# )\n",
    "\n",
    "# # Extract structured data\n",
    "# result = pipeline.predict(image_path)\n",
    "\n",
    "# # Built-in field extraction\n",
    "# for res in result:\n",
    "#     structured_data = res.json  # Contains parsed fields automatically\n",
    "#     print(structured_data['key_value_pairs'])  # Aadhaar number, name, DOB, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b297418",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A dependency error occurred during pipeline creation. Please refer to the installation documentation to ensure all required dependencies are installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDependencyError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\base.py:102\u001b[39m, in \u001b[36mPaddleXPipelineWrapper._create_paddlex_pipeline\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merged_paddlex_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m DependencyError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\__init__.py:166\u001b[39m, in \u001b[36mcreate_pipeline\u001b[39m\u001b[34m(pipeline, config, device, pp_option, use_hpip, hpi_config, *args, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m     config.pop(\u001b[33m\"\u001b[39m\u001b[33mhpi_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m pipeline = \u001b[43mBasePipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\utils\\deps.py:201\u001b[39m, in \u001b[36mpipeline_requires_extra.<locals>._deco.<locals>._wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(pipeline_cls.\u001b[34m__init__\u001b[39m)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[43mrequire_extra\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m old_init_func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\utils\\deps.py:194\u001b[39m, in \u001b[36mrequire_extra\u001b[39m\u001b[34m(extra, obj_name, alt)\u001b[39m\n\u001b[32m    193\u001b[39m     msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Alternatively, you can install `paddlex[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m DependencyError(msg)\n",
      "\u001b[31mDependencyError\u001b[39m: `PP-StructureV3` requires additional dependencies. To install them, run `pip install \"paddlex[ocr]==<PADDLEX_VERSION>\"` if youâ€™re installing `paddlex` from an index, or `pip install -e \"/path/to/PaddleX[ocr]\"` if youâ€™re installing `paddlex` locally.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpaddleocr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PPStructureV3\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# One-line structured extraction\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m pipeline = \u001b[43mPPStructureV3\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m result = pipeline.predict(image_path)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Automatic field extraction - no regex needed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\pp_structurev3.py:137\u001b[39m, in \u001b[36mPPStructureV3.__init__\u001b[39m\u001b[34m(self, layout_detection_model_name, layout_detection_model_dir, layout_threshold, layout_nms, layout_unclip_ratio, layout_merge_bboxes_mode, chart_recognition_model_name, chart_recognition_model_dir, chart_recognition_batch_size, region_detection_model_name, region_detection_model_dir, doc_orientation_classify_model_name, doc_orientation_classify_model_dir, doc_unwarping_model_name, doc_unwarping_model_dir, text_detection_model_name, text_detection_model_dir, text_det_limit_side_len, text_det_limit_type, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, textline_orientation_model_name, textline_orientation_model_dir, textline_orientation_batch_size, text_recognition_model_name, text_recognition_model_dir, text_recognition_batch_size, text_rec_score_thresh, table_classification_model_name, table_classification_model_dir, wired_table_structure_recognition_model_name, wired_table_structure_recognition_model_dir, wireless_table_structure_recognition_model_name, wireless_table_structure_recognition_model_dir, wired_table_cells_detection_model_name, wired_table_cells_detection_model_dir, wireless_table_cells_detection_model_name, wireless_table_cells_detection_model_dir, table_orientation_classify_model_name, table_orientation_classify_model_dir, seal_text_detection_model_name, seal_text_detection_model_dir, seal_det_limit_side_len, seal_det_limit_type, seal_det_thresh, seal_det_box_thresh, seal_det_unclip_ratio, seal_text_recognition_model_name, seal_text_recognition_model_dir, seal_text_recognition_batch_size, seal_rec_score_thresh, formula_recognition_model_name, formula_recognition_model_dir, formula_recognition_batch_size, use_doc_orientation_classify, use_doc_unwarping, use_textline_orientation, use_seal_recognition, use_table_recognition, use_formula_recognition, use_chart_recognition, use_region_detection, lang, ocr_version, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m params.pop(\u001b[33m\"\u001b[39m\u001b[33mkwargs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28mself\u001b[39m._params = params\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\base.py:67\u001b[39m, in \u001b[36mPaddleXPipelineWrapper.__init__\u001b[39m\u001b[34m(self, paddlex_config, **common_args)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m._common_args = parse_common_args(\n\u001b[32m     64\u001b[39m     common_args, default_enable_hpi=_DEFAULT_ENABLE_HPI\n\u001b[32m     65\u001b[39m )\n\u001b[32m     66\u001b[39m \u001b[38;5;28mself\u001b[39m._merged_paddlex_config = \u001b[38;5;28mself\u001b[39m._get_merged_paddlex_config()\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28mself\u001b[39m.paddlex_pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_paddlex_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\base.py:104\u001b[39m, in \u001b[36mPaddleXPipelineWrapper._create_paddlex_pipeline\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m create_pipeline(config=\u001b[38;5;28mself\u001b[39m._merged_paddlex_config, **kwargs)\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m DependencyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    105\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA dependency error occurred during pipeline creation. Please refer to the installation documentation to ensure all required dependencies are installed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    106\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: A dependency error occurred during pipeline creation. Please refer to the installation documentation to ensure all required dependencies are installed."
     ]
    }
   ],
   "source": [
    "# from paddleocr import PPStructureV3\n",
    "\n",
    "# # One-line structured extraction\n",
    "# pipeline = PPStructureV3(\n",
    "#     use_doc_orientation_classify=False,\n",
    "#     use_doc_unwarping=False\n",
    "# )\n",
    "# result = pipeline.predict(image_path)\n",
    "\n",
    "# # Automatic field extraction - no regex needed\n",
    "# for res in result:\n",
    "#     fields = res.get_key_value_pairs()  # Built-in function\n",
    "#     print(f\"Aadhaar Number: {fields.get('aadhaar_number')}\")\n",
    "#     print(f\"Name: {fields.get('name')}\")  \n",
    "#     print(f\"DOB: {fields.get('dob')}\")\n",
    "#     print(f\"Gender: {fields.get('gender')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9d296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mineru\n",
      "  Downloading mineru-2.2.2-py3-none-any.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.5 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.5 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.5 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/60.5 kB 262.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.5/60.5 kB 359.3 kB/s eta 0:00:00\n",
      "Collecting boto3>=1.28.43 (from mineru)\n",
      "  Downloading boto3-1.40.30-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: click>=8.1.7 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from mineru) (8.2.1)\n",
      "Collecting loguru>=0.7.2 (from mineru)\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from mineru) (1.26.4)\n",
      "Collecting pdfminer.six==20250506 (from mineru)\n",
      "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.67.1 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from mineru) (4.67.1)\n",
      "Requirement already satisfied: requests in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from mineru) (2.32.5)\n",
      "Requirement already satisfied: httpx in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from mineru) (0.28.1)\n",
      "Collecting pillow>=11.0.0 (from mineru)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pypdfium2>=4.30.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from mineru) (4.30.0)\n",
      "Collecting pypdf>=5.6.0 (from mineru)\n",
      "  Downloading pypdf-6.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting reportlab (from mineru)\n",
      "  Downloading reportlab-4.4.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pdftext>=0.6.2 (from mineru)\n",
      "  Downloading pdftext-0.6.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: modelscope>=1.26.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from mineru) (1.29.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.32.4 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from mineru) (0.34.4)\n",
      "Collecting json-repair>=0.46.2 (from mineru)\n",
      "  Downloading json_repair-0.50.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting opencv-python>=4.11.0.86 (from mineru)\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Collecting fast-langdetect<0.3.0,>=0.2.3 (from mineru)\n",
      "  Downloading fast_langdetect-0.2.5-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: scikit-image<1.0.0,>=0.25.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from mineru) (0.25.2)\n",
      "Collecting openai<2,>=1.70.0 (from mineru)\n",
      "  Downloading openai-1.107.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting beautifulsoup4<5,>=4.13.5 (from mineru)\n",
      "  Using cached beautifulsoup4-4.13.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from pdfminer.six==20250506->mineru) (3.4.3)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20250506->mineru)\n",
      "  Downloading cryptography-45.0.7-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5,>=4.13.5->mineru)\n",
      "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from beautifulsoup4<5,>=4.13.5->mineru) (4.15.0)\n",
      "Collecting botocore<1.41.0,>=1.40.30 (from boto3>=1.28.43->mineru)\n",
      "  Downloading botocore-1.40.30-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.28.43->mineru)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3>=1.28.43->mineru)\n",
      "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from click>=8.1.7->mineru) (0.4.6)\n",
      "Collecting robust-downloader>=0.0.2 (from fast-langdetect<0.3.0,>=0.2.3->mineru)\n",
      "  Downloading robust_downloader-0.0.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting fasttext-predict>=0.9.2.4 (from fast-langdetect<0.3.0,>=0.2.3->mineru)\n",
      "  Downloading fasttext_predict-0.9.2.4-cp312-cp312-win_amd64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from huggingface-hub>=0.32.4->mineru) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from huggingface-hub>=0.32.4->mineru) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from huggingface-hub>=0.32.4->mineru) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from huggingface-hub>=0.32.4->mineru) (6.0.2)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru>=0.7.2->mineru)\n",
      "  Downloading win32_setctime-1.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from modelscope>=1.26.0->mineru) (80.9.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from modelscope>=1.26.0->mineru) (2.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from openai<2,>=1.70.0->mineru) (4.10.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2,>=1.70.0->mineru)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2,>=1.70.0->mineru)\n",
      "  Downloading jiter-0.11.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from openai<2,>=1.70.0->mineru) (2.11.9)\n",
      "Requirement already satisfied: sniffio in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from openai<2,>=1.70.0->mineru) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from httpx->mineru) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from httpx->mineru) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from httpx->mineru) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from httpcore==1.*->httpx->mineru) (0.16.0)\n",
      "Collecting numpy>=1.21.6 (from mineru)\n",
      "  Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.2.1 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from pdftext>=0.6.2->mineru) (2.10.1)\n",
      "Requirement already satisfied: scipy>=1.11.4 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from scikit-image<1.0.0,>=0.25.0->mineru) (1.16.2)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from scikit-image<1.0.0,>=0.25.0->mineru) (3.5)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from scikit-image<1.0.0,>=0.25.0->mineru) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from scikit-image<1.0.0,>=0.25.0->mineru) (2025.9.9)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from scikit-image<1.0.0,>=0.25.0->mineru) (0.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from botocore<1.41.0,>=1.40.30->boto3>=1.28.43->mineru) (2.9.0.post0)\n",
      "Collecting cffi>=1.14 (from cryptography>=36.0.0->pdfminer.six==20250506->mineru)\n",
      "  Downloading cffi-2.0.0-cp312-cp312-win_amd64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from pydantic<3,>=1.9.0->openai<2,>=1.70.0->mineru) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from pydantic<3,>=1.9.0->openai<2,>=1.70.0->mineru) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from pydantic<3,>=1.9.0->openai<2,>=1.70.0->mineru) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.2.1->pdftext>=0.6.2->mineru) (1.1.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from robust-downloader>=0.0.2->fast-langdetect<0.3.0,>=0.2.3->mineru) (6.9.0)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250506->mineru)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.30->boto3>=1.28.43->mineru) (1.17.0)\n",
      "Downloading mineru-2.2.2-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.2/1.3 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.7/1.3 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 9.3 MB/s eta 0:00:00\n",
      "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.6/5.6 MB 17.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.3/5.6 MB 16.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.0/5.6 MB 14.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.7/5.6 MB 15.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.3/5.6 MB 16.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.0/5.6 MB 15.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.6 MB 15.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.6/5.6 MB 16.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 15.0 MB/s eta 0:00:00\n",
      "Using cached beautifulsoup4-4.13.5-py3-none-any.whl (105 kB)\n",
      "Downloading boto3-1.40.30-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.3/139.3 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading fast_langdetect-0.2.5-py3-none-any.whl (786 kB)\n",
      "   ---------------------------------------- 0.0/786.6 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 174.1/786.6 kB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 532.5/786.6 kB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 786.6/786.6 kB 7.1 MB/s eta 0:00:00\n",
      "Downloading json_repair-0.50.1-py3-none-any.whl (26 kB)\n",
      "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.6/61.6 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading openai-1.107.2-py3-none-any.whl (946 kB)\n",
      "   ---------------------------------------- 0.0/946.9 kB ? eta -:--:--\n",
      "   ------------- ------------------------- 327.7/946.9 kB 21.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 593.9/946.9 kB 9.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 798.7/946.9 kB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 946.9/946.9 kB 6.7 MB/s eta 0:00:00\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Downloading pdftext-0.6.3-py3-none-any.whl (23 kB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Downloading pypdf-6.0.0-py3-none-any.whl (310 kB)\n",
      "   ---------------------------------------- 0.0/310.5 kB ? eta -:--:--\n",
      "   ---------------------------------------  307.2/310.5 kB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 310.5/310.5 kB 6.4 MB/s eta 0:00:00\n",
      "Downloading reportlab-4.4.3-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 17.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/2.0 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 13.8 MB/s eta 0:00:00\n",
      "Downloading botocore-1.40.30-py3-none-any.whl (14.0 MB)\n",
      "   ---------------------------------------- 0.0/14.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/14.0 MB 14.2 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.2/14.0 MB 15.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.8/14.0 MB 14.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.5/14.0 MB 14.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.3/14.0 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.8/14.0 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.7/14.0 MB 15.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.4/14.0 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.9/14.0 MB 15.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.6/14.0 MB 15.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.1/14.0 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.7/14.0 MB 15.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.3/14.0 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.9/14.0 MB 15.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.5/14.0 MB 14.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.2/14.0 MB 14.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.9/14.0 MB 14.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.5/14.0 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.2/14.0 MB 14.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.9/14.0 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.7/14.0 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.0/14.0 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.0/14.0 MB 13.9 MB/s eta 0:00:00\n",
      "Downloading cryptography-45.0.7-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.5/3.4 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.3/3.4 MB 14.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.2/3.4 MB 15.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.0/3.4 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.4/3.4 MB 15.5 MB/s eta 0:00:00\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading fasttext_predict-0.9.2.4-cp312-cp312-win_amd64.whl (104 kB)\n",
      "   ---------------------------------------- 0.0/104.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 104.9/104.9 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading jiter-0.11.0-cp312-cp312-win_amd64.whl (203 kB)\n",
      "   ---------------------------------------- 0.0/203.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 203.5/203.5 kB 12.1 MB/s eta 0:00:00\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading robust_downloader-0.0.2-py3-none-any.whl (15 kB)\n",
      "Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.7/85.7 kB 4.7 MB/s eta 0:00:00\n",
      "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading win32_setctime-1.2.0-py3-none-any.whl (4.1 kB)\n",
      "Downloading cffi-2.0.0-cp312-cp312-win_amd64.whl (183 kB)\n",
      "   ---------------------------------------- 0.0/183.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 183.6/183.6 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "   ---------------------------------------- 0.0/118.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 118.1/118.1 kB 6.7 MB/s eta 0:00:00\n",
      "Installing collected packages: fasttext-predict, win32-setctime, soupsieve, pypdf, pycparser, pillow, numpy, json-repair, jmespath, jiter, distro, robust-downloader, reportlab, opencv-python, loguru, cffi, botocore, beautifulsoup4, s3transfer, openai, fast-langdetect, cryptography, pdftext, pdfminer.six, boto3, mineru\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 10.4.0\n",
      "    Uninstalling pillow-10.4.0:\n",
      "      Successfully uninstalled pillow-10.4.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.6.0.66\n",
      "    Uninstalling opencv-python-4.6.0.66:\n",
      "      Successfully uninstalled opencv-python-4.6.0.66\n",
      "Successfully installed beautifulsoup4-4.13.5 boto3-1.40.30 botocore-1.40.30 cffi-2.0.0 cryptography-45.0.7 distro-1.9.0 fast-langdetect-0.2.5 fasttext-predict-0.9.2.4 jiter-0.11.0 jmespath-1.0.1 json-repair-0.50.1 loguru-0.7.3 mineru-2.2.2 numpy-2.2.6 openai-1.107.2 opencv-python-4.12.0.88 pdfminer.six-20250506 pdftext-0.6.3 pillow-11.3.0 pycparser-2.23 pypdf-6.0.0 reportlab-4.4.3 robust-downloader-0.0.2 s3transfer-0.14.0 soupsieve-2.8 win32-setctime-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\~~l'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\siva_\\AppData\\Local\\Temp\\pip-uninstall-hia6a0tq'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "openbharatocr 0.4.3 requires numpy==1.26.4, but you have numpy 2.2.6 which is incompatible.\n",
      "openbharatocr 0.4.3 requires opencv-python==4.6.0.66, but you have opencv-python 4.12.0.88 which is incompatible.\n",
      "surya-ocr 0.16.7 requires pillow<11.0.0,>=10.2.0, but you have pillow 11.3.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install mineru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb250e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: paddleocr\n",
      "Version: 3.2.0\n",
      "Summary: Awesome multilingual OCR and document parsing toolkits based on PaddlePaddle\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: PaddlePaddle <Paddle-better@baidu.com>\n",
      "License: Apache License 2.0\n",
      "Location: c:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\n",
      "Requires: paddlex, PyYAML, typing-extensions\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip show paddleocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55949d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A dependency error occurred during pipeline creation. Please refer to the installation documentation to ensure all required dependencies are installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDependencyError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\base.py:102\u001b[39m, in \u001b[36mPaddleXPipelineWrapper._create_paddlex_pipeline\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merged_paddlex_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m DependencyError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\inference\\pipelines\\__init__.py:166\u001b[39m, in \u001b[36mcreate_pipeline\u001b[39m\u001b[34m(pipeline, config, device, pp_option, use_hpip, hpi_config, *args, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m     config.pop(\u001b[33m\"\u001b[39m\u001b[33mhpi_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m pipeline = \u001b[43mBasePipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hpip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhpi_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\utils\\deps.py:201\u001b[39m, in \u001b[36mpipeline_requires_extra.<locals>._deco.<locals>._wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(pipeline_cls.\u001b[34m__init__\u001b[39m)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[43mrequire_extra\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m old_init_func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddlex\\utils\\deps.py:194\u001b[39m, in \u001b[36mrequire_extra\u001b[39m\u001b[34m(extra, obj_name, alt)\u001b[39m\n\u001b[32m    193\u001b[39m     msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Alternatively, you can install `paddlex[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m DependencyError(msg)\n",
      "\u001b[31mDependencyError\u001b[39m: `PP-StructureV3` requires additional dependencies. To install them, run `pip install \"paddlex[ocr]==<PADDLEX_VERSION>\"` if youâ€™re installing `paddlex` from an index, or `pip install -e \"/path/to/PaddleX[ocr]\"` if youâ€™re installing `paddlex` locally.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpaddleocr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PPStructureV3\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m pipeline = \u001b[43mPPStructureV3\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# For Image\u001b[39;00m\n\u001b[32m     10\u001b[39m output = pipeline.predict(\n\u001b[32m     11\u001b[39m     \u001b[38;5;28minput\u001b[39m=image_path,\n\u001b[32m     12\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\pp_structurev3.py:137\u001b[39m, in \u001b[36mPPStructureV3.__init__\u001b[39m\u001b[34m(self, layout_detection_model_name, layout_detection_model_dir, layout_threshold, layout_nms, layout_unclip_ratio, layout_merge_bboxes_mode, chart_recognition_model_name, chart_recognition_model_dir, chart_recognition_batch_size, region_detection_model_name, region_detection_model_dir, doc_orientation_classify_model_name, doc_orientation_classify_model_dir, doc_unwarping_model_name, doc_unwarping_model_dir, text_detection_model_name, text_detection_model_dir, text_det_limit_side_len, text_det_limit_type, text_det_thresh, text_det_box_thresh, text_det_unclip_ratio, textline_orientation_model_name, textline_orientation_model_dir, textline_orientation_batch_size, text_recognition_model_name, text_recognition_model_dir, text_recognition_batch_size, text_rec_score_thresh, table_classification_model_name, table_classification_model_dir, wired_table_structure_recognition_model_name, wired_table_structure_recognition_model_dir, wireless_table_structure_recognition_model_name, wireless_table_structure_recognition_model_dir, wired_table_cells_detection_model_name, wired_table_cells_detection_model_dir, wireless_table_cells_detection_model_name, wireless_table_cells_detection_model_dir, table_orientation_classify_model_name, table_orientation_classify_model_dir, seal_text_detection_model_name, seal_text_detection_model_dir, seal_det_limit_side_len, seal_det_limit_type, seal_det_thresh, seal_det_box_thresh, seal_det_unclip_ratio, seal_text_recognition_model_name, seal_text_recognition_model_dir, seal_text_recognition_batch_size, seal_rec_score_thresh, formula_recognition_model_name, formula_recognition_model_dir, formula_recognition_batch_size, use_doc_orientation_classify, use_doc_unwarping, use_textline_orientation, use_seal_recognition, use_table_recognition, use_formula_recognition, use_chart_recognition, use_region_detection, lang, ocr_version, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m params.pop(\u001b[33m\"\u001b[39m\u001b[33mkwargs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28mself\u001b[39m._params = params\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\base.py:67\u001b[39m, in \u001b[36mPaddleXPipelineWrapper.__init__\u001b[39m\u001b[34m(self, paddlex_config, **common_args)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m._common_args = parse_common_args(\n\u001b[32m     64\u001b[39m     common_args, default_enable_hpi=_DEFAULT_ENABLE_HPI\n\u001b[32m     65\u001b[39m )\n\u001b[32m     66\u001b[39m \u001b[38;5;28mself\u001b[39m._merged_paddlex_config = \u001b[38;5;28mself\u001b[39m._get_merged_paddlex_config()\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28mself\u001b[39m.paddlex_pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_paddlex_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\paddleocr\\_pipelines\\base.py:104\u001b[39m, in \u001b[36mPaddleXPipelineWrapper._create_paddlex_pipeline\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m create_pipeline(config=\u001b[38;5;28mself\u001b[39m._merged_paddlex_config, **kwargs)\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m DependencyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    105\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA dependency error occurred during pipeline creation. Please refer to the installation documentation to ensure all required dependencies are installed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    106\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: A dependency error occurred during pipeline creation. Please refer to the installation documentation to ensure all required dependencies are installed."
     ]
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "# from paddleocr import PPStructureV3\n",
    "\n",
    "# pipeline = PPStructureV3(\n",
    "#     use_doc_orientation_classify=False,\n",
    "#     use_doc_unwarping=False\n",
    "# )\n",
    "\n",
    "# # For Image\n",
    "# output = pipeline.predict(\n",
    "#     input=image_path,\n",
    "# )\n",
    "\n",
    "# # Visualize the results and save the JSON results\n",
    "# for res in output:\n",
    "#     res.print() \n",
    "#     res.save_to_json(save_path=\"output\") \n",
    "#     res.save_to_markdown(save_path=\"output\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a30d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: paddlex\n",
      "Version: 3.2.1\n",
      "Summary: Low-code development tool based on PaddlePaddle.\n",
      "Home-page: \n",
      "Author: PaddlePaddle Authors\n",
      "Author-email: \n",
      "License: Apache 2.0\n",
      "Location: c:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\n",
      "Requires: aistudio_sdk, chardet, colorlog, filelock, huggingface_hub, modelscope, numpy, packaging, pandas, pillow, prettytable, py-cpuinfo, pydantic, PyYAML, requests, ruamel.yaml, typing-extensions, ujson\n",
      "Required-by: paddleocr\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip show paddlex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paddlex==3.2.1 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex[ocr]==3.2.1) (3.2.1)\n",
      "Requirement already satisfied: aistudio_sdk>=0.3.5 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (0.3.7)\n",
      "Requirement already satisfied: chardet in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (5.2.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (6.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (3.19.1)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (0.34.4)\n",
      "Requirement already satisfied: modelscope>=1.28.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (1.29.2)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (2.2.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (25.0)\n",
      "Requirement already satisfied: pandas>=1.3 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (2.3.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (11.3.0)\n",
      "Requirement already satisfied: prettytable in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (3.16.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (9.0.0)\n",
      "Requirement already satisfied: pydantic>=2 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (2.11.9)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (2.32.5)\n",
      "Requirement already satisfied: ruamel.yaml in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (0.18.15)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (4.15.0)\n",
      "Requirement already satisfied: ujson in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex==3.2.1->paddlex[ocr]==3.2.1) (5.11.0)\n",
      "Requirement already satisfied: einops in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex[ocr]==3.2.1) (0.8.1)\n",
      "Collecting ftfy (from paddlex[ocr]==3.2.1)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: imagesize in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex[ocr]==3.2.1) (1.4.1)\n",
      "Requirement already satisfied: Jinja2 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex[ocr]==3.2.1) (3.1.6)\n",
      "Collecting lxml (from paddlex[ocr]==3.2.1)\n",
      "  Using cached lxml-6.0.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: opencv-contrib-python==4.10.0.84 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex[ocr]==3.2.1) (4.10.0.84)\n",
      "Collecting openpyxl (from paddlex[ocr]==3.2.1)\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting premailer (from paddlex[ocr]==3.2.1)\n",
      "  Using cached premailer-3.10.0-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex[ocr]==3.2.1) (1.3.0.post6)\n",
      "Requirement already satisfied: pypdfium2>=4 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex[ocr]==3.2.1) (4.30.0)\n",
      "Requirement already satisfied: regex in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex[ocr]==3.2.1) (2025.9.1)\n",
      "Collecting scikit-learn (from paddlex[ocr]==3.2.1)\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: shapely in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex[ocr]==3.2.1) (2.1.1)\n",
      "Collecting tiktoken (from paddlex[ocr]==3.2.1)\n",
      "  Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tokenizers>=0.19 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from paddlex[ocr]==3.2.1) (0.22.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from aistudio_sdk>=0.3.5->paddlex==3.2.1->paddlex[ocr]==3.2.1) (7.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from aistudio_sdk>=0.3.5->paddlex==3.2.1->paddlex[ocr]==3.2.1) (4.67.1)\n",
      "Requirement already satisfied: bce-python-sdk in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from aistudio_sdk>=0.3.5->paddlex==3.2.1->paddlex[ocr]==3.2.1) (0.9.45)\n",
      "Requirement already satisfied: click in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from aistudio_sdk>=0.3.5->paddlex==3.2.1->paddlex[ocr]==3.2.1) (8.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from modelscope>=1.28.0->paddlex==3.2.1->paddlex[ocr]==3.2.1) (80.9.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from modelscope>=1.28.0->paddlex==3.2.1->paddlex[ocr]==3.2.1) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from pandas>=1.3->paddlex==3.2.1->paddlex[ocr]==3.2.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from pandas>=1.3->paddlex==3.2.1->paddlex[ocr]==3.2.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from pandas>=1.3->paddlex==3.2.1->paddlex[ocr]==3.2.1) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from pydantic>=2->paddlex==3.2.1->paddlex[ocr]==3.2.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from pydantic>=2->paddlex==3.2.1->paddlex[ocr]==3.2.1) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from pydantic>=2->paddlex==3.2.1->paddlex[ocr]==3.2.1) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from requests->paddlex==3.2.1->paddlex[ocr]==3.2.1) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from requests->paddlex==3.2.1->paddlex[ocr]==3.2.1) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from requests->paddlex==3.2.1->paddlex[ocr]==3.2.1) (2025.8.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from huggingface_hub->paddlex==3.2.1->paddlex[ocr]==3.2.1) (2025.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from colorlog->paddlex==3.2.1->paddlex[ocr]==3.2.1) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from ftfy->paddlex[ocr]==3.2.1) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from Jinja2->paddlex[ocr]==3.2.1) (3.0.2)\n",
      "Collecting et-xmlfile (from openpyxl->paddlex[ocr]==3.2.1)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting cssselect (from premailer->paddlex[ocr]==3.2.1)\n",
      "  Using cached cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cssutils (from premailer->paddlex[ocr]==3.2.1)\n",
      "  Using cached cssutils-2.11.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting cachetools (from premailer->paddlex[ocr]==3.2.1)\n",
      "  Using cached cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from ruamel.yaml->paddlex==3.2.1->paddlex[ocr]==3.2.1) (0.2.12)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from scikit-learn->paddlex[ocr]==3.2.1) (1.16.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->paddlex[ocr]==3.2.1)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->paddlex[ocr]==3.2.1)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3->paddlex==3.2.1->paddlex[ocr]==3.2.1) (1.17.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from bce-python-sdk->aistudio_sdk>=0.3.5->paddlex==3.2.1->paddlex[ocr]==3.2.1) (3.23.0)\n",
      "Requirement already satisfied: future>=0.6.0 in c:\\users\\siva_\\desktop\\projects\\capstone-aidetect\\dococr\\lib\\site-packages (from bce-python-sdk->aistudio_sdk>=0.3.5->paddlex==3.2.1->paddlex[ocr]==3.2.1) (1.0.0)\n",
      "Collecting more-itertools (from cssutils->premailer->paddlex[ocr]==3.2.1)\n",
      "  Using cached more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.8/44.8 kB 2.2 MB/s eta 0:00:00\n",
      "Using cached lxml-6.0.1-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached premailer-3.10.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.6/8.7 MB 12.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.4/8.7 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.3/8.7 MB 16.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.9/8.7 MB 16.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.6/8.7 MB 16.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.4/8.7 MB 15.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.2/8.7 MB 15.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.8/8.7 MB 16.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.5/8.7 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.2/8.7 MB 16.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.0/8.7 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.7/8.7 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 14.7 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.3 kB ? eta -:--:--\n",
      "   ------------------------------- ------- 716.8/884.3 kB 22.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 884.3/884.3 kB 13.9 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 308.4/308.4 kB 9.3 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Using cached cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
      "Using cached cssutils-2.11.1-py3-none-any.whl (385 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Using cached more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "Installing collected packages: threadpoolctl, more-itertools, lxml, joblib, ftfy, et-xmlfile, cssselect, cachetools, tiktoken, scikit-learn, openpyxl, cssutils, premailer\n",
      "Successfully installed cachetools-6.2.0 cssselect-1.3.0 cssutils-2.11.1 et-xmlfile-2.0.0 ftfy-6.3.1 joblib-1.5.2 lxml-6.0.1 more-itertools-10.8.0 openpyxl-3.1.5 premailer-3.10.0 scikit-learn-1.7.2 threadpoolctl-3.6.0 tiktoken-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install paddlex[ocr]==3.2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f104758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: surya-ocr\n",
      "Version: 0.16.7\n",
      "Summary: OCR, layout, reading order, and table recognition in 90+ languages\n",
      "Home-page: \n",
      "Author: Vik Paruchuri\n",
      "Author-email: vik.paruchuri@gmail.com\n",
      "License: GPL-3.0-or-later\n",
      "Location: c:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\n",
      "Requires: click, einops, filetype, opencv-python-headless, pillow, platformdirs, pre-commit, pydantic, pydantic-settings, pypdfium2, python-dotenv, torch, transformers\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip show surya-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbf628f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surya.ocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mocr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_ocr\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01micr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_icr\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_image\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surya.ocr'"
     ]
    }
   ],
   "source": [
    "from surya.ocr import run_ocr\n",
    "from surya.icr import run_icr\n",
    "from surya.utils import load_image\n",
    "\n",
    "# Load Aadhaar card image\n",
    "image_path = image_path\n",
    "image = load_image(image_path)\n",
    "\n",
    "# Step 1: Run OCR\n",
    "ocr_result = run_ocr([image])\n",
    "\n",
    "# Step 2: Run ICR (NER-style classification of OCR text into fields)\n",
    "icr_result = run_icr([ocr_result])\n",
    "\n",
    "# Print structured result\n",
    "print(\"Structured Aadhaar Data:\\n\", icr_result)\n",
    "\n",
    "# Example: access fields directly\n",
    "for doc in icr_result:\n",
    "    for field, value in doc.items():\n",
    "        print(f\"{field}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0b3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: surya-ocr\n",
      "Version: 0.16.7\n",
      "Summary: OCR, layout, reading order, and table recognition in 90+ languages\n",
      "Home-page: \n",
      "Author: Vik Paruchuri\n",
      "Author-email: vik.paruchuri@gmail.com\n",
      "License: GPL-3.0-or-later\n",
      "Location: c:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\n",
      "Requires: click, einops, filetype, opencv-python-headless, pillow, platformdirs, pre-commit, pydantic, pydantic-settings, pypdfium2, python-dotenv, torch, transformers\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip show surya-ocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044e71b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpython\u001b[49m -V\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# which python         # on Windows use: where python\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# python -m pip -V\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "# python -V\n",
    "# # which python         # on Windows use: where python\n",
    "# # python -m pip -V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418bb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\siva_\\AppData\\Local\\Temp\\ipykernel_30928\\591789145.py:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  ls -la | findstr /I \"surya.*\\.py\"   # Windows PowerShell/CMD\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (591789145.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mls -la | findstr /I \"surya.*\\.py\"   # Windows PowerShell/CMD\u001b[39m\n                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# # from the project folder:\n",
    "# ls -la | findstr /I \"surya.*\\.py\"   # Windows PowerShell/CMD\n",
    "# # or in *nix\n",
    "# ls -la | grep -i surya\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f712af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surya version: unknown\n",
      "surya module file: c:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\surya\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "# import surya\n",
    "# print(\"surya version:\", getattr(surya, \"__version__\", \"unknown\"))\n",
    "# print(\"surya module file:\", surya.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49dbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surya location: c:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\surya\\__init__.py\n",
      "Top-level modules:\n",
      " - common\n",
      " - detection\n",
      " - foundation\n",
      " - layout\n",
      " - logging\n",
      " - models\n",
      " - ocr_error\n",
      " - recognition\n",
      " - scripts\n",
      " - settings\n",
      " - table_rec\n"
     ]
    }
   ],
   "source": [
    "# import pkgutil\n",
    "# import surya\n",
    "\n",
    "# print(\"Surya location:\", surya.__file__)\n",
    "\n",
    "# # list top-level submodules available\n",
    "# print(\"Top-level modules:\")\n",
    "# for m in pkgutil.iter_modules(surya.__path__):\n",
    "#     print(\" -\", m.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83f182d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surya.ocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mocr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_ocr\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01micr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_icr\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_image\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surya.ocr'"
     ]
    }
   ],
   "source": [
    "from surya.ocr import run_ocr\n",
    "from surya.icr import run_icr\n",
    "from surya.utils import load_image\n",
    "from surya.recognition import run_ocr\n",
    "from surya import settings\n",
    "from PIL import Image\n",
    "\n",
    "# Load Aadhaar image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Run OCR\n",
    "ocr_result = run_ocr([image])\n",
    "\n",
    "print(\"OCR Output:\\n\", ocr_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32067bf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surya.ocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mocr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_ocr\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… surya imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surya.ocr'"
     ]
    }
   ],
   "source": [
    "from surya.ocr import run_ocr\n",
    "print(\"âœ… surya imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5806b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install surya-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "582e76e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting pytorch\n",
      "\n",
      "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py): started\n",
      "  Building wheel for pytorch (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— python setup.py bdist_wheel did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [6 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\siva_\\AppData\\Local\\Temp\\pip-install-6cg0hcyx\\pytorch_b52a78ddd671489f923db6f669545937\\setup.py\", line 15, in <module>\n",
      "          raise Exception(message)\n",
      "      Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pytorch\n",
      "ERROR: Could not build wheels for pytorch, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf64e35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613739d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.0-cp311-cp311-win_amd64.whl (109.3 MB)\n",
      "                                              0.0/109.3 MB ? eta -:--:--\n",
      "                                              0.1/109.3 MB 1.1 MB/s eta 0:01:41\n",
      "                                              0.3/109.3 MB 2.8 MB/s eta 0:00:39\n",
      "                                              0.7/109.3 MB 5.3 MB/s eta 0:00:21\n",
      "                                             1.8/109.3 MB 10.4 MB/s eta 0:00:11\n",
      "     -                                       3.1/109.3 MB 14.0 MB/s eta 0:00:08\n",
      "     -                                       4.1/109.3 MB 15.6 MB/s eta 0:00:07\n",
      "     --                                      5.7/109.3 MB 18.2 MB/s eta 0:00:06\n",
      "     --                                      7.3/109.3 MB 20.3 MB/s eta 0:00:06\n",
      "     ---                                     8.8/109.3 MB 21.6 MB/s eta 0:00:05\n",
      "     ---                                    10.1/109.3 MB 22.2 MB/s eta 0:00:05\n",
      "     ----                                   11.7/109.3 MB 31.2 MB/s eta 0:00:04\n",
      "     ----                                   13.5/109.3 MB 32.7 MB/s eta 0:00:03\n",
      "     -----                                  15.0/109.3 MB 32.7 MB/s eta 0:00:03\n",
      "     -----                                  16.6/109.3 MB 32.8 MB/s eta 0:00:03\n",
      "     ------                                 18.3/109.3 MB 34.4 MB/s eta 0:00:03\n",
      "     ------                                 19.9/109.3 MB 34.4 MB/s eta 0:00:03\n",
      "     -------                                21.0/109.3 MB 32.8 MB/s eta 0:00:03\n",
      "     -------                                22.2/109.3 MB 31.2 MB/s eta 0:00:03\n",
      "     --------                               23.7/109.3 MB 31.2 MB/s eta 0:00:03\n",
      "     --------                               25.2/109.3 MB 31.2 MB/s eta 0:00:03\n",
      "     ---------                              26.4/109.3 MB 29.7 MB/s eta 0:00:03\n",
      "     ---------                              27.7/109.3 MB 31.2 MB/s eta 0:00:03\n",
      "     ----------                             29.0/109.3 MB 29.8 MB/s eta 0:00:03\n",
      "     ----------                             30.1/109.3 MB 29.7 MB/s eta 0:00:03\n",
      "     -----------                            31.7/109.3 MB 29.8 MB/s eta 0:00:03\n",
      "     -----------                            33.2/109.3 MB 31.2 MB/s eta 0:00:03\n",
      "     ------------                           34.8/109.3 MB 29.7 MB/s eta 0:00:03\n",
      "     ------------                           36.5/109.3 MB 31.2 MB/s eta 0:00:03\n",
      "     -------------                          38.0/109.3 MB 31.1 MB/s eta 0:00:03\n",
      "     -------------                          39.6/109.3 MB 31.2 MB/s eta 0:00:03\n",
      "     --------------                         41.1/109.3 MB 31.2 MB/s eta 0:00:03\n",
      "     --------------                         42.7/109.3 MB 31.2 MB/s eta 0:00:03\n",
      "     ---------------                        44.4/109.3 MB 32.7 MB/s eta 0:00:02\n",
      "     ----------------                       46.0/109.3 MB 32.7 MB/s eta 0:00:02\n",
      "     ----------------                       47.1/109.3 MB 32.7 MB/s eta 0:00:02\n",
      "     ----------------                       48.6/109.3 MB 32.7 MB/s eta 0:00:02\n",
      "     -----------------                      49.7/109.3 MB 31.1 MB/s eta 0:00:02\n",
      "     -----------------                      51.2/109.3 MB 31.2 MB/s eta 0:00:02\n",
      "     ------------------                     52.9/109.3 MB 32.8 MB/s eta 0:00:02\n",
      "     ------------------                     54.5/109.3 MB 32.8 MB/s eta 0:00:02\n",
      "     -------------------                    55.8/109.3 MB 31.2 MB/s eta 0:00:02\n",
      "     -------------------                    57.2/109.3 MB 31.2 MB/s eta 0:00:02\n",
      "     --------------------                   58.6/109.3 MB 31.2 MB/s eta 0:00:02\n",
      "     --------------------                   59.8/109.3 MB 31.2 MB/s eta 0:00:02\n",
      "     ---------------------                  60.5/109.3 MB 28.4 MB/s eta 0:00:02\n",
      "     ---------------------                  61.9/109.3 MB 27.3 MB/s eta 0:00:02\n",
      "     ----------------------                 63.4/109.3 MB 27.3 MB/s eta 0:00:02\n",
      "     ----------------------                 64.7/109.3 MB 27.3 MB/s eta 0:00:02\n",
      "     ----------------------                 66.0/109.3 MB 27.3 MB/s eta 0:00:02\n",
      "     -----------------------                67.5/109.3 MB 27.3 MB/s eta 0:00:02\n",
      "     -----------------------                68.6/109.3 MB 27.3 MB/s eta 0:00:02\n",
      "     ------------------------               70.1/109.3 MB 27.3 MB/s eta 0:00:02\n",
      "     ------------------------               71.2/109.3 MB 28.4 MB/s eta 0:00:02\n",
      "     -------------------------              72.4/109.3 MB 28.5 MB/s eta 0:00:02\n",
      "     -------------------------              73.8/109.3 MB 29.7 MB/s eta 0:00:02\n",
      "     --------------------------             74.9/109.3 MB 28.4 MB/s eta 0:00:02\n",
      "     --------------------------             76.4/109.3 MB 29.8 MB/s eta 0:00:02\n",
      "     --------------------------             77.5/109.3 MB 28.5 MB/s eta 0:00:02\n",
      "     ---------------------------            78.8/109.3 MB 29.7 MB/s eta 0:00:02\n",
      "     ---------------------------            80.3/109.3 MB 28.5 MB/s eta 0:00:02\n",
      "     ----------------------------           81.7/109.3 MB 28.5 MB/s eta 0:00:01\n",
      "     ----------------------------           83.2/109.3 MB 29.7 MB/s eta 0:00:01\n",
      "     -----------------------------          84.3/109.3 MB 29.7 MB/s eta 0:00:01\n",
      "     -----------------------------          85.8/109.3 MB 28.4 MB/s eta 0:00:01\n",
      "     ------------------------------         87.1/109.3 MB 28.5 MB/s eta 0:00:01\n",
      "     ------------------------------         88.1/109.3 MB 28.4 MB/s eta 0:00:01\n",
      "     ------------------------------         89.2/109.3 MB 27.3 MB/s eta 0:00:01\n",
      "     -------------------------------        90.2/109.3 MB 27.3 MB/s eta 0:00:01\n",
      "     -------------------------------        91.6/109.3 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------       92.8/109.3 MB 26.2 MB/s eta 0:00:01\n",
      "     --------------------------------       93.7/109.3 MB 25.1 MB/s eta 0:00:01\n",
      "     ---------------------------------      95.2/109.3 MB 25.1 MB/s eta 0:00:01\n",
      "     ---------------------------------      96.5/109.3 MB 25.2 MB/s eta 0:00:01\n",
      "     ---------------------------------      97.4/109.3 MB 24.2 MB/s eta 0:00:01\n",
      "     ----------------------------------     98.3/109.3 MB 22.6 MB/s eta 0:00:01\n",
      "     ----------------------------------     99.7/109.3 MB 24.2 MB/s eta 0:00:01\n",
      "     ----------------------------------    101.0/109.3 MB 24.2 MB/s eta 0:00:01\n",
      "     ----------------------------------    102.4/109.3 MB 24.3 MB/s eta 0:00:01\n",
      "     -----------------------------------   103.7/109.3 MB 24.2 MB/s eta 0:00:01\n",
      "     -----------------------------------   105.0/109.3 MB 24.2 MB/s eta 0:00:01\n",
      "     -----------------------------------   106.2/109.3 MB 24.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  106.8/109.3 MB 23.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  107.7/109.3 MB 22.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  108.6/109.3 MB 23.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  109.3/109.3 MB 22.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 109.3/109.3 MB 7.1 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.0-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "                                              0.0/4.0 MB ? eta -:--:--\n",
      "     ---------                                0.9/4.0 MB 29.1 MB/s eta 0:00:01\n",
      "     ------------------------                 2.4/4.0 MB 25.6 MB/s eta 0:00:01\n",
      "     -------------------------------------    3.8/4.0 MB 26.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.0/4.0 MB 23.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-2.9.0 torchvision-0.24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lmdeploy 0.7.2.post1 requires torch<=2.5.1,>=2.0.0, but you have torch 2.9.0 which is incompatible.\n",
      "lmdeploy 0.7.2.post1 requires torchvision<=0.20.1,>=0.15.0, but you have torchvision 0.24.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4e9e40",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:281\u001b[0m\n\u001b[0;32m    277\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    279\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 281\u001b[0m     _load_dll_libraries()\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# Libraries can either be in\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m# path/nvidia/lib_folder/lib or\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# path/lib_folder/lib\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:264\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    260\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    261\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    263\u001b[0m     )\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2667b4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.9.0Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uninstalling torch-2.9.0:\n",
      "  Successfully uninstalled torch-2.9.0\n",
      "Found existing installation: torchvision 0.24.0\n",
      "Uninstalling torchvision-0.24.0:\n",
      "  Successfully uninstalled torchvision-0.24.0\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21218a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://download.pytorch.org/whl/cpu/torch-2.9.0%2Bcpu-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torch-2.9.0%2Bcpu-cp311-cp311-win_amd64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://download.pytorch.org/whl/cpu/torchvision-0.24.0%2Bcpu-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchvision-0.24.0%2Bcpu-cp311-cp311-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://download.pytorch.org/whl/cpu/torchaudio-2.9.0%2Bcpu-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.9.0%2Bcpu-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torch-2.9.0%2Bcpu-cp311-cp311-win_amd64.whl (109.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torchvision-0.24.0%2Bcpu-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.9.0%2Bcpu-cp311-cp311-win_amd64.whl (662 kB)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torch-2.9.0%2Bcpu-cp311-cp311-win_amd64.whl (109.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torchvision-0.24.0%2Bcpu-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.9.0%2Bcpu-cp311-cp311-win_amd64.whl (662 kB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.9.0+cpu torchaudio-2.9.0+cpu torchvision-0.24.0+cpu\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lmdeploy 0.7.2.post1 requires torch<=2.5.1,>=2.0.0, but you have torch 2.9.0+cpu which is incompatible.\n",
      "lmdeploy 0.7.2.post1 requires torchvision<=0.20.1,>=0.15.0, but you have torchvision 0.24.0+cpu which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf8f481",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:281\u001b[0m\n\u001b[0;32m    277\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    279\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 281\u001b[0m     _load_dll_libraries()\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# Libraries can either be in\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m# path/nvidia/lib_folder/lib or\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# path/lib_folder/lib\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:264\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    260\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    261\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    263\u001b[0m     )\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # Should print False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ddc711",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pip uninstall torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f48f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch==2.5.1+cpu torchvision==0.20.1+cpu torchaudio==2.5.1+cpu --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2572d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surya.common.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurya\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrecognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecognitionPredictor\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurya\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayoutPredictor\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurya\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m SuryaImage\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Load models\u001b[39;00m\n\u001b[32m      9\u001b[39m det_model = DetectionPredictor.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mvikp/surya-detection\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'surya.common.data'"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from PIL import Image\n",
    "# from surya.detection import DetectionPredictor\n",
    "# from surya.recognition import RecognitionPredictor\n",
    "# from surya.layout import LayoutPredictor\n",
    "# from surya.common.data import Image as SuryaImage\n",
    "\n",
    "# # Load models\n",
    "# det_model = DetectionPredictor.from_pretrained(\"vikp/surya-detection\")\n",
    "# rec_model = RecognitionPredictor.from_pretrained(\"vikp/surya-recognition\")\n",
    "# layout_model = LayoutPredictor.from_pretrained(\"vikp/surya-layout\")\n",
    "\n",
    "# # Load Aadhaar image\n",
    "# image_path = image_path\n",
    "# pil_img = Image.open(image_path).convert(\"RGB\")\n",
    "# img = SuryaImage(pil_img)\n",
    "\n",
    "# # Step 1: Text detection\n",
    "# det_results = det_model.predict([img])\n",
    "\n",
    "# # Step 2: Text recognition\n",
    "# rec_results = rec_model.predict([img], det_results)\n",
    "\n",
    "# # Step 3: (Optional) Layout parsing\n",
    "# layout_results = layout_model.predict([img])\n",
    "\n",
    "# # Final OCR result = recognition output\n",
    "# ocr_text = \" \".join([r.text for r in rec_results[0]])\n",
    "# print(\"OCR Text:\", ocr_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfde69c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surya.common.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurya\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdetection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DetectionPredictor\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurya\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrecognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecognitionPredictor\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurya\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m SuryaImage\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Load models\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'surya.common.data'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from surya.detection import DetectionPredictor\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.common.data import Image as SuryaImage\n",
    "from transformers import pipeline\n",
    "\n",
    "# ---------------------------\n",
    "# Load models\n",
    "# ---------------------------\n",
    "det_model = DetectionPredictor.from_pretrained(\"vikp/surya-detection\")\n",
    "rec_model = RecognitionPredictor.from_pretrained(\"vikp/surya-recognition\")\n",
    "\n",
    "# HuggingFace NER (you can fine-tune later for Aadhaar-specific fields)\n",
    "ner_pipeline = pipeline(\"token-classification\", \n",
    "                        model=\"dslim/bert-base-NER\", \n",
    "                        aggregation_strategy=\"simple\")\n",
    "\n",
    "# ---------------------------\n",
    "# OCR Function\n",
    "# ---------------------------\n",
    "def run_surya_ocr(image_path):\n",
    "    pil_img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = SuryaImage(pil_img)\n",
    "\n",
    "    # Step 1: Text detection\n",
    "    det_results = det_model.predict([img])\n",
    "\n",
    "    # Step 2: Text recognition\n",
    "    rec_results = rec_model.predict([img], det_results)\n",
    "\n",
    "    # Extract recognized text\n",
    "    ocr_text = \" \".join([r.text for r in rec_results[0]])\n",
    "    return ocr_text\n",
    "\n",
    "# ---------------------------\n",
    "# Aadhaar Field Extraction\n",
    "# ---------------------------\n",
    "def extract_aadhaar_fields(ocr_text):\n",
    "    entities = ner_pipeline(ocr_text)\n",
    "\n",
    "    # Simple mapping: (youâ€™ll fine-tune later)\n",
    "    fields = {\n",
    "        \"aadhaar_number\": None,\n",
    "        \"name\": None,\n",
    "        \"dob\": None,\n",
    "        \"gender\": None\n",
    "    }\n",
    "\n",
    "    for ent in entities:\n",
    "        label = ent[\"entity_group\"]\n",
    "        word = ent[\"word\"]\n",
    "\n",
    "        if label == \"CARDINAL\" or label == \"NUMBER\":\n",
    "            if len(word.replace(\" \", \"\")) >= 12:  # Aadhaar has 12 digits\n",
    "                fields[\"aadhaar_number\"] = word.replace(\" \", \"\")\n",
    "        elif label == \"PER\":\n",
    "            fields[\"name\"] = word\n",
    "        elif label == \"DATE\":\n",
    "            fields[\"dob\"] = word\n",
    "        elif label in [\"MISC\", \"ORG\"]:\n",
    "            if word.lower() in [\"male\", \"female\", \"m\", \"f\"]:\n",
    "                fields[\"gender\"] = word.capitalize()\n",
    "\n",
    "    return fields\n",
    "\n",
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"aadhaar_sample.jpg\"\n",
    "\n",
    "    # 1. OCR\n",
    "    text = run_surya_ocr(image_path)\n",
    "    print(\"\\nOCR Text:\", text)\n",
    "\n",
    "    # 2. Extract fields\n",
    "    extracted = extract_aadhaar_fields(text)\n",
    "    print(\"\\nStructured Aadhaar JSON:\\n\", extracted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cebe542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules in surya.common:\n",
      " - load\n",
      " - polygon\n",
      " - predictor\n",
      " - pretrained\n",
      " - s3\n",
      " - surya\n",
      " - util\n"
     ]
    }
   ],
   "source": [
    "# import pkgutil, surya.common\n",
    "# print(\"Modules in surya.common:\")\n",
    "# for m in pkgutil.iter_modules(surya.common.__path__):\n",
    "#     print(\" -\", m.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557977d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'DetectionPredictor' has no attribute 'from_pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Load models\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m det_model = \u001b[43mDetectionPredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mvikp/surya-detection\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m rec_model = RecognitionPredictor.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mvikp/surya-recognition\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# HuggingFace NER for Aadhaar entities\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'DetectionPredictor' has no attribute 'from_pretrained'"
     ]
    }
   ],
   "source": [
    "# from PIL import Image\n",
    "# import torch\n",
    "# from surya.detection import DetectionPredictor\n",
    "# from surya.recognition import RecognitionPredictor\n",
    "# from transformers import pipeline\n",
    "\n",
    "# # ---------------------------\n",
    "# # Load models\n",
    "# # ---------------------------\n",
    "# det_model = DetectionPredictor.from_pretrained(\"vikp/surya-detection\")\n",
    "# rec_model = RecognitionPredictor.from_pretrained(\"vikp/surya-recognition\")\n",
    "\n",
    "# # HuggingFace NER for Aadhaar entities\n",
    "# ner_pipeline = pipeline(\n",
    "#     \"token-classification\", \n",
    "#     model=\"dslim/bert-base-NER\", \n",
    "#     aggregation_strategy=\"simple\"\n",
    "# )\n",
    "\n",
    "# def run_surya_ocr(image_path):\n",
    "#     # Load image\n",
    "#     pil_img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "#     # Run detection + recognition\n",
    "#     det_results = det_model.predict([pil_img])\n",
    "#     rec_results = rec_model.predict([pil_img], det_results)\n",
    "\n",
    "#     # Extract raw OCR text\n",
    "#     ocr_text = \" \".join([r.text for r in rec_results[0]])\n",
    "#     return ocr_text\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     text = run_surya_ocr(image_path)\n",
    "#     print(\"\\nOCR Text:\\n\", text)\n",
    "\n",
    "#     # Run NER to get structured Aadhaar entities\n",
    "#     entities = ner_pipeline(text)\n",
    "#     print(\"\\nExtracted Entities:\\n\", entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a859250",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=r\"C:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\aadhar3.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e05e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2238bf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siva_\\Desktop\\PROJECTS\\CAPSTONE-AIDETECT\\dococr\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Detecting bboxes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.89s/it]\n",
      "Recognizing Text: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:51<00:00,  6.41s/it]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from surya.foundation import FoundationPredictor\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor\n",
    "\n",
    "image = Image.open(image_path)\n",
    "foundation_predictor = FoundationPredictor()\n",
    "recognition_predictor = RecognitionPredictor(foundation_predictor)\n",
    "detection_predictor = DetectionPredictor()\n",
    "\n",
    "predictions = recognition_predictor([image], det_predictor=detection_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5065540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OCRResult(text_lines=[TextLine(polygon=[[243.0, 33.0], [369.0, 24.0], [371.0, 52.0], [245.0, 61.0]], confidence=0.9980400303999583, text='à¤­à¤¾à¤°à¤¤ à¤¸à¤°à¤•à¤¾à¤°', chars=[TextChar(polygon=[[243.0, 24.0], [243.0, 25.0], [244.0, 25.0], [244.0, 24.0]], confidence=0.9985871315002441, text='', bbox_valid=False, bbox=[243.0, 24.0, 244.0, 25.0]), TextChar(polygon=[[243.0, 24.0], [243.0, 25.0], [244.0, 25.0], [244.0, 24.0]], confidence=0.9939873218536377, text='', bbox_valid=False, bbox=[243.0, 24.0, 244.0, 25.0]), TextChar(polygon=[[248.0, 25.0], [277.0, 24.0], [277.0, 59.0], [248.0, 59.0]], confidence=0.9922506213188171, text='à¤­', bbox_valid=True, bbox=[248.0, 24.0, 277.0, 59.0]), TextChar(polygon=[[250.0, 24.0], [276.0, 24.0], [276.0, 60.0], [250.0, 60.0]], confidence=0.9992941617965698, text='à¤¾', bbox_valid=True, bbox=[250.0, 24.0, 276.0, 60.0]), TextChar(polygon=[[274.0, 25.0], [285.0, 24.0], [285.0, 60.0], [274.0, 60.0]], confidence=0.9999570846557617, text='à¤°', bbox_valid=True, bbox=[274.0, 24.0, 285.0, 60.0]), TextChar(polygon=[[284.0, 25.0], [300.0, 25.0], [300.0, 59.0], [284.0, 60.0]], confidence=0.9998859167098999, text='à¤¤', bbox_valid=True, bbox=[284.0, 25.0, 300.0, 60.0]), TextChar(polygon=[[295.0, 25.0], [305.0, 25.0], [305.0, 59.0], [295.0, 59.0]], confidence=0.9978417158126831, text=' ', bbox_valid=True, bbox=[295.0, 25.0, 305.0, 59.0]), TextChar(polygon=[[302.0, 25.0], [317.0, 25.0], [317.0, 59.0], [301.0, 59.0]], confidence=0.9994511008262634, text='à¤¸', bbox_valid=True, bbox=[301.0, 25.0, 317.0, 59.0]), TextChar(polygon=[[313.0, 25.0], [324.0, 25.0], [324.0, 59.0], [313.0, 60.0]], confidence=0.9976679682731628, text='à¤°', bbox_valid=True, bbox=[313.0, 25.0, 324.0, 60.0]), TextChar(polygon=[[319.0, 25.0], [343.0, 25.0], [342.0, 59.0], [319.0, 59.0]], confidence=0.999923825263977, text='à¤•', bbox_valid=True, bbox=[319.0, 25.0, 343.0, 59.0]), TextChar(polygon=[[320.0, 24.0], [345.0, 24.0], [344.0, 60.0], [320.0, 60.0]], confidence=0.9992393255233765, text='à¤¾', bbox_valid=True, bbox=[320.0, 24.0, 345.0, 60.0]), TextChar(polygon=[[340.0, 25.0], [350.0, 25.0], [349.0, 60.0], [339.0, 60.0]], confidence=0.9983941912651062, text='à¤°', bbox_valid=True, bbox=[339.0, 25.0, 350.0, 60.0])], original_text_good=False, words=[], bbox=[243.0, 24.0, 371.0, 61.0]), TextLine(polygon=[[199.0, 78.0], [404.0, 66.0], [405.0, 99.0], [201.0, 112.0]], confidence=0.9866534868876139, text='Government of India', chars=[TextChar(polygon=[[199.0, 66.0], [199.0, 67.0], [200.0, 67.0], [200.0, 66.0]], confidence=0.9974306225776672, text='', bbox_valid=False, bbox=[199.0, 66.0, 200.0, 67.0]), TextChar(polygon=[[199.0, 66.0], [199.0, 67.0], [200.0, 67.0], [200.0, 66.0]], confidence=0.9976527094841003, text='', bbox_valid=False, bbox=[199.0, 66.0, 200.0, 67.0]), TextChar(polygon=[[274.0, 73.0], [294.0, 73.0], [294.0, 101.0], [274.0, 102.0]], confidence=0.7373882532119751, text='G', bbox_valid=True, bbox=[274.0, 73.0, 294.0, 102.0]), TextChar(polygon=[[277.0, 73.0], [291.0, 73.0], [291.0, 103.0], [277.0, 103.0]], confidence=0.9998929500579834, text='o', bbox_valid=True, bbox=[277.0, 73.0, 291.0, 103.0]), TextChar(polygon=[[280.0, 73.0], [295.0, 73.0], [295.0, 103.0], [280.0, 103.0]], confidence=0.9999315738677979, text='v', bbox_valid=True, bbox=[280.0, 73.0, 295.0, 103.0]), TextChar(polygon=[[275.0, 72.0], [290.0, 72.0], [290.0, 104.0], [275.0, 104.0]], confidence=0.999954342842102, text='e', bbox_valid=True, bbox=[275.0, 72.0, 290.0, 104.0]), TextChar(polygon=[[279.0, 73.0], [289.0, 73.0], [289.0, 103.0], [279.0, 103.0]], confidence=0.9999843835830688, text='r', bbox_valid=True, bbox=[279.0, 73.0, 289.0, 103.0]), TextChar(polygon=[[282.0, 73.0], [295.0, 73.0], [295.0, 104.0], [282.0, 104.0]], confidence=0.9999977350234985, text='n', bbox_valid=True, bbox=[282.0, 73.0, 295.0, 104.0]), TextChar(polygon=[[285.0, 73.0], [301.0, 73.0], [301.0, 103.0], [285.0, 103.0]], confidence=0.9999833106994629, text='m', bbox_valid=True, bbox=[285.0, 73.0, 301.0, 103.0]), TextChar(polygon=[[293.0, 73.0], [305.0, 73.0], [305.0, 102.0], [293.0, 103.0]], confidence=0.9999958276748657, text='e', bbox_valid=True, bbox=[293.0, 73.0, 305.0, 103.0]), TextChar(polygon=[[302.0, 72.0], [315.0, 72.0], [315.0, 104.0], [302.0, 104.0]], confidence=0.9999793767929077, text='n', bbox_valid=True, bbox=[302.0, 72.0, 315.0, 104.0]), TextChar(polygon=[[306.0, 75.0], [313.0, 75.0], [313.0, 102.0], [306.0, 102.0]], confidence=0.9999568462371826, text='t', bbox_valid=True, bbox=[306.0, 75.0, 313.0, 102.0]), TextChar(polygon=[[304.0, 74.0], [313.0, 74.0], [313.0, 103.0], [304.0, 103.0]], confidence=0.9957560896873474, text=' ', bbox_valid=True, bbox=[304.0, 74.0, 313.0, 103.0]), TextChar(polygon=[[308.0, 74.0], [321.0, 74.0], [321.0, 103.0], [308.0, 103.0]], confidence=0.9987058639526367, text='o', bbox_valid=True, bbox=[308.0, 74.0, 321.0, 103.0]), TextChar(polygon=[[308.0, 74.0], [317.0, 74.0], [317.0, 102.0], [308.0, 102.0]], confidence=0.9999597072601318, text='f', bbox_valid=True, bbox=[308.0, 74.0, 317.0, 102.0]), TextChar(polygon=[[303.0, 73.0], [313.0, 73.0], [313.0, 101.0], [303.0, 101.0]], confidence=0.9993415474891663, text=' ', bbox_valid=True, bbox=[303.0, 73.0, 313.0, 101.0]), TextChar(polygon=[[305.0, 73.0], [312.0, 73.0], [312.0, 102.0], [305.0, 102.0]], confidence=0.9945249557495117, text='I', bbox_valid=True, bbox=[305.0, 73.0, 312.0, 102.0]), TextChar(polygon=[[303.0, 72.0], [317.0, 72.0], [317.0, 104.0], [303.0, 104.0]], confidence=0.999971866607666, text='n', bbox_valid=True, bbox=[303.0, 72.0, 317.0, 104.0]), TextChar(polygon=[[301.0, 73.0], [315.0, 73.0], [315.0, 103.0], [301.0, 103.0]], confidence=0.9999480247497559, text='d', bbox_valid=True, bbox=[301.0, 73.0, 315.0, 103.0]), TextChar(polygon=[[321.0, 73.0], [327.0, 73.0], [327.0, 103.0], [321.0, 103.0]], confidence=0.9993811845779419, text='i', bbox_valid=True, bbox=[321.0, 73.0, 327.0, 103.0]), TextChar(polygon=[[311.0, 73.0], [323.0, 73.0], [323.0, 103.0], [311.0, 103.0]], confidence=0.9999860525131226, text='a', bbox_valid=True, bbox=[311.0, 73.0, 323.0, 103.0])], original_text_good=False, words=[], bbox=[199.0, 66.0, 405.0, 112.0]), TextLine(polygon=[[165.0, 137.0], [233.0, 137.0], [233.0, 166.0], [165.0, 166.0]], confidence=0.995894363948277, text='à¤°à¤¿à¤¯à¤¾à¤¸à¤¤', chars=[TextChar(polygon=[[165.0, 137.0], [165.0, 138.0], [166.0, 138.0], [166.0, 137.0]], confidence=0.9973227381706238, text='', bbox_valid=False, bbox=[165.0, 137.0, 166.0, 138.0]), TextChar(polygon=[[170.0, 137.0], [186.0, 137.0], [186.0, 165.0], [170.0, 165.0]], confidence=0.9745302200317383, text='à¤°', bbox_valid=True, bbox=[170.0, 137.0, 186.0, 165.0]), TextChar(polygon=[[171.0, 137.0], [186.0, 137.0], [185.0, 165.0], [171.0, 165.0]], confidence=0.9999532699584961, text='à¤¿', bbox_valid=True, bbox=[171.0, 137.0, 186.0, 165.0]), TextChar(polygon=[[184.0, 137.0], [200.0, 137.0], [200.0, 165.0], [184.0, 165.0]], confidence=0.9999014139175415, text='à¤¯', bbox_valid=True, bbox=[184.0, 137.0, 200.0, 165.0]), TextChar(polygon=[[184.0, 137.0], [200.0, 137.0], [200.0, 165.0], [184.0, 165.0]], confidence=0.9999464750289917, text='à¤¾', bbox_valid=True, bbox=[184.0, 137.0, 200.0, 165.0]), TextChar(polygon=[[199.0, 137.0], [212.0, 137.0], [212.0, 165.0], [199.0, 165.0]], confidence=0.999840497970581, text='à¤¸', bbox_valid=True, bbox=[199.0, 137.0, 212.0, 165.0]), TextChar(polygon=[[213.0, 137.0], [224.0, 137.0], [224.0, 165.0], [212.0, 165.0]], confidence=0.999765932559967, text='à¤¤', bbox_valid=True, bbox=[212.0, 137.0, 224.0, 165.0])], original_text_good=False, words=[], bbox=[165.0, 137.0, 233.0, 166.0]), TextLine(polygon=[[163.0, 184.0], [250.0, 179.0], [252.0, 210.0], [164.0, 214.0]], confidence=0.9557280763983727, text='Riyasat', chars=[TextChar(polygon=[[163.0, 179.0], [163.0, 180.0], [164.0, 180.0], [164.0, 179.0]], confidence=0.9966822266578674, text='', bbox_valid=False, bbox=[163.0, 179.0, 164.0, 180.0]), TextChar(polygon=[[181.0, 179.0], [197.0, 179.0], [197.0, 211.0], [181.0, 211.0]], confidence=0.6888231635093689, text='R', bbox_valid=True, bbox=[181.0, 179.0, 197.0, 211.0]), TextChar(polygon=[[191.0, 179.0], [197.0, 179.0], [197.0, 212.0], [191.0, 212.0]], confidence=0.9980427026748657, text='i', bbox_valid=True, bbox=[191.0, 179.0, 197.0, 212.0]), TextChar(polygon=[[194.0, 179.0], [206.0, 179.0], [205.0, 212.0], [193.0, 212.0]], confidence=0.9666933417320251, text='y', bbox_valid=True, bbox=[193.0, 179.0, 206.0, 212.0]), TextChar(polygon=[[201.0, 179.0], [213.0, 179.0], [213.0, 212.0], [201.0, 212.0]], confidence=0.9996786117553711, text='a', bbox_valid=True, bbox=[201.0, 179.0, 213.0, 212.0]), TextChar(polygon=[[208.0, 179.0], [217.0, 179.0], [217.0, 211.0], [208.0, 211.0]], confidence=0.9992973804473877, text='s', bbox_valid=True, bbox=[208.0, 179.0, 217.0, 211.0]), TextChar(polygon=[[212.0, 179.0], [224.0, 179.0], [224.0, 212.0], [212.0, 212.0]], confidence=0.9974390268325806, text='a', bbox_valid=True, bbox=[212.0, 179.0, 224.0, 212.0]), TextChar(polygon=[[214.0, 179.0], [224.0, 179.0], [224.0, 211.0], [214.0, 211.0]], confidence=0.9991681575775146, text='t', bbox_valid=True, bbox=[214.0, 179.0, 224.0, 211.0])], original_text_good=False, words=[], bbox=[163.0, 179.0, 252.0, 214.0]), TextLine(polygon=[[159.0, 222.0], [446.0, 208.0], [447.0, 244.0], [161.0, 258.0]], confidence=0.9854952323025671, text='à¤œà¤¨à¥à¤® à¤¤à¤¿à¤¥à¤¿/ DOB: 01/01/1991', chars=[TextChar(polygon=[[159.0, 208.0], [159.0, 209.0], [160.0, 209.0], [160.0, 208.0]], confidence=0.9489918947219849, text='', bbox_valid=False, bbox=[159.0, 208.0, 160.0, 209.0]), TextChar(polygon=[[159.0, 208.0], [159.0, 209.0], [160.0, 209.0], [160.0, 208.0]], confidence=0.722760021686554, text='', bbox_valid=False, bbox=[159.0, 208.0, 160.0, 209.0]), TextChar(polygon=[[159.0, 208.0], [159.0, 209.0], [160.0, 209.0], [160.0, 208.0]], confidence=0.9600530862808228, text='', bbox_valid=False, bbox=[159.0, 208.0, 160.0, 209.0]), TextChar(polygon=[[166.0, 219.0], [182.0, 219.0], [182.0, 257.0], [166.0, 257.0]], confidence=0.9976078271865845, text='à¤œ', bbox_valid=True, bbox=[166.0, 219.0, 182.0, 257.0]), TextChar(polygon=[[180.0, 219.0], [197.0, 219.0], [197.0, 257.0], [180.0, 257.0]], confidence=0.9999395608901978, text='à¤¨', bbox_valid=True, bbox=[180.0, 219.0, 197.0, 257.0]), TextChar(polygon=[[182.0, 219.0], [204.0, 219.0], [203.0, 257.0], [181.0, 257.0]], confidence=0.9995007514953613, text='à¥', bbox_valid=True, bbox=[181.0, 219.0, 204.0, 257.0]), TextChar(polygon=[[181.0, 219.0], [203.0, 219.0], [203.0, 257.0], [181.0, 257.0]], confidence=0.9999812841415405, text='à¤®', bbox_valid=True, bbox=[181.0, 219.0, 203.0, 257.0]), TextChar(polygon=[[202.0, 218.0], [210.0, 218.0], [209.0, 257.0], [201.0, 257.0]], confidence=0.9986585378646851, text=' ', bbox_valid=True, bbox=[201.0, 218.0, 210.0, 257.0]), TextChar(polygon=[[207.0, 218.0], [227.0, 218.0], [227.0, 257.0], [207.0, 257.0]], confidence=0.9976497292518616, text='à¤¤', bbox_valid=True, bbox=[207.0, 218.0, 227.0, 257.0]), TextChar(polygon=[[206.0, 219.0], [227.0, 218.0], [227.0, 257.0], [206.0, 257.0]], confidence=0.9994279742240906, text='à¤¿', bbox_valid=True, bbox=[206.0, 218.0, 227.0, 257.0]), TextChar(polygon=[[225.0, 217.0], [248.0, 217.0], [248.0, 257.0], [225.0, 257.0]], confidence=0.9807953238487244, text='à¤¥', bbox_valid=True, bbox=[225.0, 217.0, 248.0, 257.0]), TextChar(polygon=[[224.0, 217.0], [247.0, 217.0], [247.0, 257.0], [224.0, 257.0]], confidence=0.9989620447158813, text='à¤¿', bbox_valid=True, bbox=[224.0, 217.0, 247.0, 257.0]), TextChar(polygon=[[244.0, 216.0], [255.0, 216.0], [255.0, 257.0], [244.0, 257.0]], confidence=0.9931667447090149, text='/', bbox_valid=True, bbox=[244.0, 216.0, 255.0, 257.0]), TextChar(polygon=[[253.0, 216.0], [261.0, 215.0], [261.0, 257.0], [253.0, 257.0]], confidence=0.9883307218551636, text=' ', bbox_valid=True, bbox=[253.0, 215.0, 261.0, 257.0]), TextChar(polygon=[[258.0, 215.0], [276.0, 215.0], [276.0, 257.0], [258.0, 257.0]], confidence=0.9985026121139526, text='D', bbox_valid=True, bbox=[258.0, 215.0, 276.0, 257.0]), TextChar(polygon=[[274.0, 214.0], [294.0, 214.0], [294.0, 256.0], [274.0, 257.0]], confidence=0.998955488204956, text='O', bbox_valid=True, bbox=[274.0, 214.0, 294.0, 257.0]), TextChar(polygon=[[293.0, 214.0], [310.0, 214.0], [310.0, 256.0], [293.0, 256.0]], confidence=0.9993127584457397, text='B', bbox_valid=True, bbox=[293.0, 214.0, 310.0, 256.0]), TextChar(polygon=[[305.0, 213.0], [315.0, 213.0], [315.0, 255.0], [305.0, 256.0]], confidence=0.9995840191841125, text=':', bbox_valid=True, bbox=[305.0, 213.0, 315.0, 256.0]), TextChar(polygon=[[312.0, 213.0], [320.0, 212.0], [320.0, 255.0], [312.0, 256.0]], confidence=0.9992989301681519, text=' ', bbox_valid=True, bbox=[312.0, 212.0, 320.0, 256.0]), TextChar(polygon=[[318.0, 212.0], [335.0, 212.0], [335.0, 254.0], [318.0, 254.0]], confidence=0.9986963868141174, text='0', bbox_valid=True, bbox=[318.0, 212.0, 335.0, 254.0]), TextChar(polygon=[[334.0, 211.0], [349.0, 211.0], [349.0, 254.0], [334.0, 254.0]], confidence=0.9999121427536011, text='1', bbox_valid=True, bbox=[334.0, 211.0, 349.0, 254.0]), TextChar(polygon=[[347.0, 210.0], [357.0, 210.0], [357.0, 254.0], [347.0, 254.0]], confidence=0.9998584985733032, text='/', bbox_valid=True, bbox=[347.0, 210.0, 357.0, 254.0]), TextChar(polygon=[[354.0, 210.0], [369.0, 210.0], [368.0, 253.0], [354.0, 254.0]], confidence=0.9999644756317139, text='0', bbox_valid=True, bbox=[354.0, 210.0, 369.0, 254.0]), TextChar(polygon=[[368.0, 209.0], [382.0, 209.0], [382.0, 253.0], [367.0, 253.0]], confidence=0.99986732006073, text='1', bbox_valid=True, bbox=[367.0, 209.0, 382.0, 253.0]), TextChar(polygon=[[381.0, 209.0], [391.0, 209.0], [390.0, 253.0], [380.0, 253.0]], confidence=0.9999489784240723, text='/', bbox_valid=True, bbox=[380.0, 209.0, 391.0, 253.0]), TextChar(polygon=[[389.0, 209.0], [403.0, 209.0], [402.0, 253.0], [388.0, 253.0]], confidence=0.9998396635055542, text='1', bbox_valid=True, bbox=[388.0, 209.0, 403.0, 253.0]), TextChar(polygon=[[399.0, 209.0], [414.0, 209.0], [414.0, 252.0], [399.0, 252.0]], confidence=0.9999369382858276, text='9', bbox_valid=True, bbox=[399.0, 209.0, 414.0, 252.0]), TextChar(polygon=[[412.0, 208.0], [427.0, 208.0], [426.0, 252.0], [411.0, 252.0]], confidence=0.9999566078186035, text='9', bbox_valid=True, bbox=[411.0, 208.0, 427.0, 252.0]), TextChar(polygon=[[425.0, 208.0], [439.0, 208.0], [438.0, 251.0], [424.0, 251.0]], confidence=0.9999014139175415, text='1', bbox_valid=True, bbox=[424.0, 208.0, 439.0, 251.0])], original_text_good=False, words=[], bbox=[159.0, 208.0, 447.0, 258.0]), TextLine(polygon=[[158.0, 270.0], [288.0, 263.0], [290.0, 296.0], [160.0, 303.0]], confidence=0.9658514300982157, text='à¤ªà¥à¤°à¥à¤· / MALE', chars=[TextChar(polygon=[[158.0, 263.0], [158.0, 264.0], [159.0, 264.0], [159.0, 263.0]], confidence=0.9401918649673462, text='', bbox_valid=False, bbox=[158.0, 263.0, 159.0, 264.0]), TextChar(polygon=[[158.0, 263.0], [158.0, 264.0], [159.0, 264.0], [159.0, 263.0]], confidence=0.8066011667251587, text='', bbox_valid=False, bbox=[158.0, 263.0, 159.0, 264.0]), TextChar(polygon=[[158.0, 263.0], [158.0, 264.0], [159.0, 264.0], [159.0, 263.0]], confidence=0.8752935528755188, text='', bbox_valid=False, bbox=[158.0, 263.0, 159.0, 264.0]), TextChar(polygon=[[170.0, 264.0], [183.0, 264.0], [183.0, 301.0], [170.0, 301.0]], confidence=0.929167628288269, text='à¤ª', bbox_valid=True, bbox=[170.0, 264.0, 183.0, 301.0]), TextChar(polygon=[[171.0, 264.0], [184.0, 264.0], [184.0, 301.0], [171.0, 301.0]], confidence=0.9882060289382935, text='à¥', bbox_valid=True, bbox=[171.0, 264.0, 184.0, 301.0]), TextChar(polygon=[[180.0, 264.0], [191.0, 263.0], [191.0, 301.0], [180.0, 301.0]], confidence=0.9994679093360901, text='à¤°', bbox_valid=True, bbox=[180.0, 263.0, 191.0, 301.0]), TextChar(polygon=[[180.0, 264.0], [194.0, 264.0], [194.0, 300.0], [180.0, 301.0]], confidence=0.9997968077659607, text='à¥', bbox_valid=True, bbox=[180.0, 264.0, 194.0, 301.0]), TextChar(polygon=[[190.0, 264.0], [203.0, 264.0], [203.0, 300.0], [190.0, 301.0]], confidence=0.9998002648353577, text='à¤·', bbox_valid=True, bbox=[190.0, 264.0, 203.0, 301.0]), TextChar(polygon=[[203.0, 264.0], [212.0, 264.0], [212.0, 300.0], [202.0, 300.0]], confidence=0.9926481246948242, text=' ', bbox_valid=True, bbox=[202.0, 264.0, 212.0, 300.0]), TextChar(polygon=[[208.0, 264.0], [220.0, 264.0], [220.0, 300.0], [208.0, 300.0]], confidence=0.9917005896568298, text='/', bbox_valid=True, bbox=[208.0, 264.0, 220.0, 300.0]), TextChar(polygon=[[214.0, 264.0], [221.0, 264.0], [221.0, 300.0], [214.0, 300.0]], confidence=0.9722787141799927, text=' ', bbox_valid=True, bbox=[214.0, 264.0, 221.0, 300.0]), TextChar(polygon=[[221.0, 264.0], [238.0, 264.0], [238.0, 300.0], [221.0, 300.0]], confidence=0.9930480122566223, text='M', bbox_valid=True, bbox=[221.0, 264.0, 238.0, 300.0]), TextChar(polygon=[[238.0, 264.0], [252.0, 264.0], [252.0, 300.0], [238.0, 300.0]], confidence=0.999840497970581, text='A', bbox_valid=True, bbox=[238.0, 264.0, 252.0, 300.0]), TextChar(polygon=[[249.0, 264.0], [262.0, 264.0], [261.0, 300.0], [249.0, 300.0]], confidence=0.9999088048934937, text='L', bbox_valid=True, bbox=[249.0, 264.0, 262.0, 300.0]), TextChar(polygon=[[256.0, 265.0], [269.0, 265.0], [269.0, 299.0], [256.0, 300.0]], confidence=0.9998214840888977, text='E', bbox_valid=True, bbox=[256.0, 265.0, 269.0, 300.0])], original_text_good=False, words=[], bbox=[158.0, 263.0, 290.0, 303.0]), TextLine(polygon=[[176.0, 432.0], [409.0, 417.0], [412.0, 457.0], [178.0, 472.0]], confidence=0.9962854743003845, text='6754 3973 8680', chars=[TextChar(polygon=[[176.0, 417.0], [176.0, 418.0], [177.0, 418.0], [177.0, 417.0]], confidence=0.9931279420852661, text='', bbox_valid=False, bbox=[176.0, 417.0, 177.0, 418.0]), TextChar(polygon=[[190.0, 427.0], [215.0, 427.0], [215.0, 469.0], [190.0, 469.0]], confidence=0.957194983959198, text='6', bbox_valid=True, bbox=[190.0, 427.0, 215.0, 469.0]), TextChar(polygon=[[203.0, 426.0], [223.0, 425.0], [223.0, 470.0], [203.0, 471.0]], confidence=0.9998175501823425, text='7', bbox_valid=True, bbox=[203.0, 425.0, 223.0, 471.0]), TextChar(polygon=[[218.0, 425.0], [237.0, 425.0], [236.0, 471.0], [217.0, 471.0]], confidence=0.9999736547470093, text='5', bbox_valid=True, bbox=[217.0, 425.0, 237.0, 471.0]), TextChar(polygon=[[234.0, 425.0], [253.0, 424.0], [253.0, 470.0], [234.0, 470.0]], confidence=0.9996740818023682, text='4', bbox_valid=True, bbox=[234.0, 424.0, 253.0, 470.0]), TextChar(polygon=[[251.0, 425.0], [263.0, 424.0], [263.0, 469.0], [250.0, 469.0]], confidence=0.9959576725959778, text=' ', bbox_valid=True, bbox=[250.0, 424.0, 263.0, 469.0]), TextChar(polygon=[[259.0, 424.0], [275.0, 424.0], [275.0, 469.0], [258.0, 469.0]], confidence=0.9996823072433472, text='3', bbox_valid=True, bbox=[258.0, 424.0, 275.0, 469.0]), TextChar(polygon=[[273.0, 423.0], [291.0, 423.0], [291.0, 469.0], [273.0, 469.0]], confidence=0.9999079704284668, text='9', bbox_valid=True, bbox=[273.0, 423.0, 291.0, 469.0]), TextChar(polygon=[[290.0, 422.0], [309.0, 422.0], [308.0, 468.0], [289.0, 469.0]], confidence=0.9999840259552002, text='7', bbox_valid=True, bbox=[289.0, 422.0, 309.0, 469.0]), TextChar(polygon=[[306.0, 421.0], [324.0, 421.0], [324.0, 468.0], [306.0, 469.0]], confidence=0.9999533891677856, text='3', bbox_valid=True, bbox=[306.0, 421.0, 324.0, 469.0]), TextChar(polygon=[[319.0, 421.0], [331.0, 420.0], [330.0, 467.0], [319.0, 467.0]], confidence=0.9993025064468384, text=' ', bbox_valid=True, bbox=[319.0, 420.0, 331.0, 467.0]), TextChar(polygon=[[326.0, 420.0], [345.0, 420.0], [345.0, 467.0], [326.0, 467.0]], confidence=0.9998806715011597, text='8', bbox_valid=True, bbox=[326.0, 420.0, 345.0, 467.0]), TextChar(polygon=[[342.0, 420.0], [361.0, 419.0], [361.0, 466.0], [342.0, 467.0]], confidence=0.9999345541000366, text='6', bbox_valid=True, bbox=[342.0, 419.0, 361.0, 467.0]), TextChar(polygon=[[360.0, 419.0], [378.0, 419.0], [378.0, 466.0], [359.0, 467.0]], confidence=0.9999502897262573, text='8', bbox_valid=True, bbox=[359.0, 419.0, 378.0, 467.0]), TextChar(polygon=[[371.0, 420.0], [390.0, 419.0], [389.0, 465.0], [370.0, 466.0]], confidence=0.9999405145645142, text='0', bbox_valid=True, bbox=[370.0, 419.0, 390.0, 466.0])], original_text_good=False, words=[], bbox=[176.0, 417.0, 412.0, 472.0]), TextLine(polygon=[[74.0, 496.0], [486.0, 461.0], [490.0, 519.0], [78.0, 554.0]], confidence=0.9996950393137725, text='à¤®à¥‡à¤°à¤¾ à¤†à¤§à¤¾à¤°, à¤®à¥‡à¤°à¥€ à¤ªà¤¹à¤šà¤¾à¤¨', chars=[TextChar(polygon=[[74.0, 461.0], [74.0, 462.0], [75.0, 462.0], [75.0, 461.0]], confidence=0.9992971420288086, text='', bbox_valid=False, bbox=[74.0, 461.0, 75.0, 462.0]), TextChar(polygon=[[74.0, 461.0], [74.0, 462.0], [75.0, 462.0], [75.0, 461.0]], confidence=0.9962446093559265, text='', bbox_valid=False, bbox=[74.0, 461.0, 75.0, 462.0]), TextChar(polygon=[[84.0, 484.0], [123.0, 483.0], [123.0, 552.0], [84.0, 553.0]], confidence=0.9995649456977844, text='à¤®', bbox_valid=True, bbox=[84.0, 483.0, 123.0, 553.0]), TextChar(polygon=[[81.0, 484.0], [120.0, 483.0], [120.0, 553.0], [81.0, 553.0]], confidence=0.9998641014099121, text='à¥‡', bbox_valid=True, bbox=[81.0, 483.0, 120.0, 553.0]), TextChar(polygon=[[115.0, 482.0], [153.0, 481.0], [153.0, 552.0], [115.0, 553.0]], confidence=0.9998942613601685, text='à¤°', bbox_valid=True, bbox=[115.0, 481.0, 153.0, 553.0]), TextChar(polygon=[[112.0, 482.0], [148.0, 482.0], [148.0, 552.0], [112.0, 553.0]], confidence=0.9999836683273315, text='à¤¾', bbox_valid=True, bbox=[112.0, 482.0, 148.0, 553.0]), TextChar(polygon=[[149.0, 481.0], [174.0, 480.0], [173.0, 551.0], [148.0, 552.0]], confidence=0.9999653100967407, text=' ', bbox_valid=True, bbox=[148.0, 480.0, 174.0, 552.0]), TextChar(polygon=[[167.0, 479.0], [216.0, 479.0], [215.0, 551.0], [166.0, 551.0]], confidence=0.9999295473098755, text='à¤†', bbox_valid=True, bbox=[166.0, 479.0, 216.0, 551.0]), TextChar(polygon=[[206.0, 478.0], [256.0, 477.0], [256.0, 549.0], [206.0, 550.0]], confidence=0.999996542930603, text='à¤§', bbox_valid=True, bbox=[206.0, 477.0, 256.0, 550.0]), TextChar(polygon=[[201.0, 477.0], [249.0, 476.0], [249.0, 550.0], [201.0, 551.0]], confidence=0.999963641166687, text='à¤¾', bbox_valid=True, bbox=[201.0, 476.0, 249.0, 551.0]), TextChar(polygon=[[243.0, 475.0], [265.0, 474.0], [265.0, 548.0], [243.0, 549.0]], confidence=0.9999685287475586, text='à¤°', bbox_valid=True, bbox=[243.0, 474.0, 265.0, 549.0]), TextChar(polygon=[[261.0, 474.0], [276.0, 474.0], [276.0, 547.0], [261.0, 548.0]], confidence=0.9998047947883606, text=',', bbox_valid=True, bbox=[261.0, 474.0, 276.0, 548.0]), TextChar(polygon=[[270.0, 475.0], [295.0, 474.0], [294.0, 547.0], [269.0, 548.0]], confidence=0.9999470710754395, text=' ', bbox_valid=True, bbox=[269.0, 474.0, 295.0, 548.0]), TextChar(polygon=[[290.0, 474.0], [324.0, 473.0], [324.0, 547.0], [290.0, 548.0]], confidence=0.999910831451416, text='à¤®', bbox_valid=True, bbox=[290.0, 473.0, 324.0, 548.0]), TextChar(polygon=[[285.0, 474.0], [319.0, 473.0], [319.0, 547.0], [285.0, 548.0]], confidence=0.9999560117721558, text='à¥‡', bbox_valid=True, bbox=[285.0, 473.0, 319.0, 548.0]), TextChar(polygon=[[315.0, 472.0], [353.0, 471.0], [353.0, 545.0], [315.0, 546.0]], confidence=0.9999610185623169, text='à¤°', bbox_valid=True, bbox=[315.0, 471.0, 353.0, 546.0]), TextChar(polygon=[[315.0, 471.0], [348.0, 470.0], [348.0, 545.0], [315.0, 546.0]], confidence=0.9999854564666748, text='à¥€', bbox_valid=True, bbox=[315.0, 470.0, 348.0, 546.0]), TextChar(polygon=[[340.0, 472.0], [366.0, 471.0], [365.0, 545.0], [339.0, 545.0]], confidence=0.9999492168426514, text=' ', bbox_valid=True, bbox=[339.0, 471.0, 366.0, 545.0]), TextChar(polygon=[[364.0, 470.0], [391.0, 469.0], [390.0, 544.0], [363.0, 545.0]], confidence=0.9999663829803467, text='à¤ª', bbox_valid=True, bbox=[363.0, 469.0, 391.0, 545.0]), TextChar(polygon=[[381.0, 470.0], [410.0, 469.0], [410.0, 543.0], [381.0, 544.0]], confidence=0.9999741315841675, text='à¤¹', bbox_valid=True, bbox=[381.0, 469.0, 410.0, 544.0]), TextChar(polygon=[[395.0, 469.0], [445.0, 469.0], [444.0, 541.0], [394.0, 542.0]], confidence=0.9989213943481445, text='à¤š', bbox_valid=True, bbox=[394.0, 469.0, 445.0, 542.0]), TextChar(polygon=[[398.0, 466.0], [448.0, 465.0], [447.0, 541.0], [397.0, 542.0]], confidence=0.9999845027923584, text='à¤¾', bbox_valid=True, bbox=[397.0, 465.0, 448.0, 542.0]), TextChar(polygon=[[439.0, 465.0], [471.0, 464.0], [470.0, 540.0], [438.0, 540.0]], confidence=0.9999527931213379, text='à¤¨', bbox_valid=True, bbox=[438.0, 464.0, 471.0, 540.0])], original_text_good=False, words=[], bbox=[74.0, 461.0, 490.0, 554.0])], image_bbox=[0.0, 0.0, 640.0, 640.0])]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0fa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siva_\\Desktop\\PROJECTS\\st_scalefusion_realtime\\newvenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'image_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurya\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrecognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecognitionPredictor\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurya\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdetection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DetectionPredictor\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m image = Image.open(\u001b[43mimage_path\u001b[49m)\n\u001b[32m      7\u001b[39m foundation_predictor = FoundationPredictor()\n\u001b[32m      8\u001b[39m recognition_predictor = RecognitionPredictor(foundation_predictor)\n",
      "\u001b[31mNameError\u001b[39m: name 'image_path' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from surya.foundation import FoundationPredictor\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor\n",
    "\n",
    "image = Image.open(image_path)\n",
    "foundation_predictor = FoundationPredictor()\n",
    "recognition_predictor = RecognitionPredictor(foundation_predictor)\n",
    "detection_predictor = DetectionPredictor()\n",
    "\n",
    "predictions = recognition_predictor([image], det_predictor=detection_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b84706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\siva_\\anaconda3\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (4.65.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16fb992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OCRResult(text_lines=[TextLine(polygon=[[243.0, 33.0], [369.0, 24.0], [371.0, 52.0], [245.0, 61.0]], confidence=0.9980400303999583, text='à¤­à¤¾à¤°à¤¤ à¤¸à¤°à¤•à¤¾à¤°', chars=[TextChar(polygon=[[243.0, 24.0], [243.0, 25.0], [244.0, 25.0], [244.0, 24.0]], confidence=0.9985871315002441, text='', bbox_valid=False, bbox=[243.0, 24.0, 244.0, 25.0]), TextChar(polygon=[[243.0, 24.0], [243.0, 25.0], [244.0, 25.0], [244.0, 24.0]], confidence=0.9939873218536377, text='', bbox_valid=False, bbox=[243.0, 24.0, 244.0, 25.0]), TextChar(polygon=[[248.0, 25.0], [277.0, 24.0], [277.0, 59.0], [248.0, 59.0]], confidence=0.9922506213188171, text='à¤­', bbox_valid=True, bbox=[248.0, 24.0, 277.0, 59.0]), TextChar(polygon=[[250.0, 24.0], [276.0, 24.0], [276.0, 60.0], [250.0, 60.0]], confidence=0.9992941617965698, text='à¤¾', bbox_valid=True, bbox=[250.0, 24.0, 276.0, 60.0]), TextChar(polygon=[[274.0, 25.0], [285.0, 24.0], [285.0, 60.0], [274.0, 60.0]], confidence=0.9999570846557617, text='à¤°', bbox_valid=True, bbox=[274.0, 24.0, 285.0, 60.0]), TextChar(polygon=[[284.0, 25.0], [300.0, 25.0], [300.0, 59.0], [284.0, 60.0]], confidence=0.9998859167098999, text='à¤¤', bbox_valid=True, bbox=[284.0, 25.0, 300.0, 60.0]), TextChar(polygon=[[295.0, 25.0], [305.0, 25.0], [305.0, 59.0], [295.0, 59.0]], confidence=0.9978417158126831, text=' ', bbox_valid=True, bbox=[295.0, 25.0, 305.0, 59.0]), TextChar(polygon=[[302.0, 25.0], [317.0, 25.0], [317.0, 59.0], [301.0, 59.0]], confidence=0.9994511008262634, text='à¤¸', bbox_valid=True, bbox=[301.0, 25.0, 317.0, 59.0]), TextChar(polygon=[[313.0, 25.0], [324.0, 25.0], [324.0, 59.0], [313.0, 60.0]], confidence=0.9976679682731628, text='à¤°', bbox_valid=True, bbox=[313.0, 25.0, 324.0, 60.0]), TextChar(polygon=[[319.0, 25.0], [343.0, 25.0], [342.0, 59.0], [319.0, 59.0]], confidence=0.999923825263977, text='à¤•', bbox_valid=True, bbox=[319.0, 25.0, 343.0, 59.0]), TextChar(polygon=[[320.0, 24.0], [345.0, 24.0], [344.0, 60.0], [320.0, 60.0]], confidence=0.9992393255233765, text='à¤¾', bbox_valid=True, bbox=[320.0, 24.0, 345.0, 60.0]), TextChar(polygon=[[340.0, 25.0], [350.0, 25.0], [349.0, 60.0], [339.0, 60.0]], confidence=0.9983941912651062, text='à¤°', bbox_valid=True, bbox=[339.0, 25.0, 350.0, 60.0])], original_text_good=False, words=[], bbox=[243.0, 24.0, 371.0, 61.0]), TextLine(polygon=[[199.0, 78.0], [404.0, 66.0], [405.0, 99.0], [201.0, 112.0]], confidence=0.9866534868876139, text='Government of India', chars=[TextChar(polygon=[[199.0, 66.0], [199.0, 67.0], [200.0, 67.0], [200.0, 66.0]], confidence=0.9974306225776672, text='', bbox_valid=False, bbox=[199.0, 66.0, 200.0, 67.0]), TextChar(polygon=[[199.0, 66.0], [199.0, 67.0], [200.0, 67.0], [200.0, 66.0]], confidence=0.9976527094841003, text='', bbox_valid=False, bbox=[199.0, 66.0, 200.0, 67.0]), TextChar(polygon=[[274.0, 73.0], [294.0, 73.0], [294.0, 101.0], [274.0, 102.0]], confidence=0.7373882532119751, text='G', bbox_valid=True, bbox=[274.0, 73.0, 294.0, 102.0]), TextChar(polygon=[[277.0, 73.0], [291.0, 73.0], [291.0, 103.0], [277.0, 103.0]], confidence=0.9998929500579834, text='o', bbox_valid=True, bbox=[277.0, 73.0, 291.0, 103.0]), TextChar(polygon=[[280.0, 73.0], [295.0, 73.0], [295.0, 103.0], [280.0, 103.0]], confidence=0.9999315738677979, text='v', bbox_valid=True, bbox=[280.0, 73.0, 295.0, 103.0]), TextChar(polygon=[[275.0, 72.0], [290.0, 72.0], [290.0, 104.0], [275.0, 104.0]], confidence=0.999954342842102, text='e', bbox_valid=True, bbox=[275.0, 72.0, 290.0, 104.0]), TextChar(polygon=[[279.0, 73.0], [289.0, 73.0], [289.0, 103.0], [279.0, 103.0]], confidence=0.9999843835830688, text='r', bbox_valid=True, bbox=[279.0, 73.0, 289.0, 103.0]), TextChar(polygon=[[282.0, 73.0], [295.0, 73.0], [295.0, 104.0], [282.0, 104.0]], confidence=0.9999977350234985, text='n', bbox_valid=True, bbox=[282.0, 73.0, 295.0, 104.0]), TextChar(polygon=[[285.0, 73.0], [301.0, 73.0], [301.0, 103.0], [285.0, 103.0]], confidence=0.9999833106994629, text='m', bbox_valid=True, bbox=[285.0, 73.0, 301.0, 103.0]), TextChar(polygon=[[293.0, 73.0], [305.0, 73.0], [305.0, 102.0], [293.0, 103.0]], confidence=0.9999958276748657, text='e', bbox_valid=True, bbox=[293.0, 73.0, 305.0, 103.0]), TextChar(polygon=[[302.0, 72.0], [315.0, 72.0], [315.0, 104.0], [302.0, 104.0]], confidence=0.9999793767929077, text='n', bbox_valid=True, bbox=[302.0, 72.0, 315.0, 104.0]), TextChar(polygon=[[306.0, 75.0], [313.0, 75.0], [313.0, 102.0], [306.0, 102.0]], confidence=0.9999568462371826, text='t', bbox_valid=True, bbox=[306.0, 75.0, 313.0, 102.0]), TextChar(polygon=[[304.0, 74.0], [313.0, 74.0], [313.0, 103.0], [304.0, 103.0]], confidence=0.9957560896873474, text=' ', bbox_valid=True, bbox=[304.0, 74.0, 313.0, 103.0]), TextChar(polygon=[[308.0, 74.0], [321.0, 74.0], [321.0, 103.0], [308.0, 103.0]], confidence=0.9987058639526367, text='o', bbox_valid=True, bbox=[308.0, 74.0, 321.0, 103.0]), TextChar(polygon=[[308.0, 74.0], [317.0, 74.0], [317.0, 102.0], [308.0, 102.0]], confidence=0.9999597072601318, text='f', bbox_valid=True, bbox=[308.0, 74.0, 317.0, 102.0]), TextChar(polygon=[[303.0, 73.0], [313.0, 73.0], [313.0, 101.0], [303.0, 101.0]], confidence=0.9993415474891663, text=' ', bbox_valid=True, bbox=[303.0, 73.0, 313.0, 101.0]), TextChar(polygon=[[305.0, 73.0], [312.0, 73.0], [312.0, 102.0], [305.0, 102.0]], confidence=0.9945249557495117, text='I', bbox_valid=True, bbox=[305.0, 73.0, 312.0, 102.0]), TextChar(polygon=[[303.0, 72.0], [317.0, 72.0], [317.0, 104.0], [303.0, 104.0]], confidence=0.999971866607666, text='n', bbox_valid=True, bbox=[303.0, 72.0, 317.0, 104.0]), TextChar(polygon=[[301.0, 73.0], [315.0, 73.0], [315.0, 103.0], [301.0, 103.0]], confidence=0.9999480247497559, text='d', bbox_valid=True, bbox=[301.0, 73.0, 315.0, 103.0]), TextChar(polygon=[[321.0, 73.0], [327.0, 73.0], [327.0, 103.0], [321.0, 103.0]], confidence=0.9993811845779419, text='i', bbox_valid=True, bbox=[321.0, 73.0, 327.0, 103.0]), TextChar(polygon=[[311.0, 73.0], [323.0, 73.0], [323.0, 103.0], [311.0, 103.0]], confidence=0.9999860525131226, text='a', bbox_valid=True, bbox=[311.0, 73.0, 323.0, 103.0])], original_text_good=False, words=[], bbox=[199.0, 66.0, 405.0, 112.0]), TextLine(polygon=[[165.0, 137.0], [233.0, 137.0], [233.0, 166.0], [165.0, 166.0]], confidence=0.995894363948277, text='à¤°à¤¿à¤¯à¤¾à¤¸à¤¤', chars=[TextChar(polygon=[[165.0, 137.0], [165.0, 138.0], [166.0, 138.0], [166.0, 137.0]], confidence=0.9973227381706238, text='', bbox_valid=False, bbox=[165.0, 137.0, 166.0, 138.0]), TextChar(polygon=[[170.0, 137.0], [186.0, 137.0], [186.0, 165.0], [170.0, 165.0]], confidence=0.9745302200317383, text='à¤°', bbox_valid=True, bbox=[170.0, 137.0, 186.0, 165.0]), TextChar(polygon=[[171.0, 137.0], [186.0, 137.0], [185.0, 165.0], [171.0, 165.0]], confidence=0.9999532699584961, text='à¤¿', bbox_valid=True, bbox=[171.0, 137.0, 186.0, 165.0]), TextChar(polygon=[[184.0, 137.0], [200.0, 137.0], [200.0, 165.0], [184.0, 165.0]], confidence=0.9999014139175415, text='à¤¯', bbox_valid=True, bbox=[184.0, 137.0, 200.0, 165.0]), TextChar(polygon=[[184.0, 137.0], [200.0, 137.0], [200.0, 165.0], [184.0, 165.0]], confidence=0.9999464750289917, text='à¤¾', bbox_valid=True, bbox=[184.0, 137.0, 200.0, 165.0]), TextChar(polygon=[[199.0, 137.0], [212.0, 137.0], [212.0, 165.0], [199.0, 165.0]], confidence=0.999840497970581, text='à¤¸', bbox_valid=True, bbox=[199.0, 137.0, 212.0, 165.0]), TextChar(polygon=[[213.0, 137.0], [224.0, 137.0], [224.0, 165.0], [212.0, 165.0]], confidence=0.999765932559967, text='à¤¤', bbox_valid=True, bbox=[212.0, 137.0, 224.0, 165.0])], original_text_good=False, words=[], bbox=[165.0, 137.0, 233.0, 166.0]), TextLine(polygon=[[163.0, 184.0], [250.0, 179.0], [252.0, 210.0], [164.0, 214.0]], confidence=0.9557280763983727, text='Riyasat', chars=[TextChar(polygon=[[163.0, 179.0], [163.0, 180.0], [164.0, 180.0], [164.0, 179.0]], confidence=0.9966822266578674, text='', bbox_valid=False, bbox=[163.0, 179.0, 164.0, 180.0]), TextChar(polygon=[[181.0, 179.0], [197.0, 179.0], [197.0, 211.0], [181.0, 211.0]], confidence=0.6888231635093689, text='R', bbox_valid=True, bbox=[181.0, 179.0, 197.0, 211.0]), TextChar(polygon=[[191.0, 179.0], [197.0, 179.0], [197.0, 212.0], [191.0, 212.0]], confidence=0.9980427026748657, text='i', bbox_valid=True, bbox=[191.0, 179.0, 197.0, 212.0]), TextChar(polygon=[[194.0, 179.0], [206.0, 179.0], [205.0, 212.0], [193.0, 212.0]], confidence=0.9666933417320251, text='y', bbox_valid=True, bbox=[193.0, 179.0, 206.0, 212.0]), TextChar(polygon=[[201.0, 179.0], [213.0, 179.0], [213.0, 212.0], [201.0, 212.0]], confidence=0.9996786117553711, text='a', bbox_valid=True, bbox=[201.0, 179.0, 213.0, 212.0]), TextChar(polygon=[[208.0, 179.0], [217.0, 179.0], [217.0, 211.0], [208.0, 211.0]], confidence=0.9992973804473877, text='s', bbox_valid=True, bbox=[208.0, 179.0, 217.0, 211.0]), TextChar(polygon=[[212.0, 179.0], [224.0, 179.0], [224.0, 212.0], [212.0, 212.0]], confidence=0.9974390268325806, text='a', bbox_valid=True, bbox=[212.0, 179.0, 224.0, 212.0]), TextChar(polygon=[[214.0, 179.0], [224.0, 179.0], [224.0, 211.0], [214.0, 211.0]], confidence=0.9991681575775146, text='t', bbox_valid=True, bbox=[214.0, 179.0, 224.0, 211.0])], original_text_good=False, words=[], bbox=[163.0, 179.0, 252.0, 214.0]), TextLine(polygon=[[159.0, 222.0], [446.0, 208.0], [447.0, 244.0], [161.0, 258.0]], confidence=0.9854952323025671, text='à¤œà¤¨à¥à¤® à¤¤à¤¿à¤¥à¤¿/ DOB: 01/01/1991', chars=[TextChar(polygon=[[159.0, 208.0], [159.0, 209.0], [160.0, 209.0], [160.0, 208.0]], confidence=0.9489918947219849, text='', bbox_valid=False, bbox=[159.0, 208.0, 160.0, 209.0]), TextChar(polygon=[[159.0, 208.0], [159.0, 209.0], [160.0, 209.0], [160.0, 208.0]], confidence=0.722760021686554, text='', bbox_valid=False, bbox=[159.0, 208.0, 160.0, 209.0]), TextChar(polygon=[[159.0, 208.0], [159.0, 209.0], [160.0, 209.0], [160.0, 208.0]], confidence=0.9600530862808228, text='', bbox_valid=False, bbox=[159.0, 208.0, 160.0, 209.0]), TextChar(polygon=[[166.0, 219.0], [182.0, 219.0], [182.0, 257.0], [166.0, 257.0]], confidence=0.9976078271865845, text='à¤œ', bbox_valid=True, bbox=[166.0, 219.0, 182.0, 257.0]), TextChar(polygon=[[180.0, 219.0], [197.0, 219.0], [197.0, 257.0], [180.0, 257.0]], confidence=0.9999395608901978, text='à¤¨', bbox_valid=True, bbox=[180.0, 219.0, 197.0, 257.0]), TextChar(polygon=[[182.0, 219.0], [204.0, 219.0], [203.0, 257.0], [181.0, 257.0]], confidence=0.9995007514953613, text='à¥', bbox_valid=True, bbox=[181.0, 219.0, 204.0, 257.0]), TextChar(polygon=[[181.0, 219.0], [203.0, 219.0], [203.0, 257.0], [181.0, 257.0]], confidence=0.9999812841415405, text='à¤®', bbox_valid=True, bbox=[181.0, 219.0, 203.0, 257.0]), TextChar(polygon=[[202.0, 218.0], [210.0, 218.0], [209.0, 257.0], [201.0, 257.0]], confidence=0.9986585378646851, text=' ', bbox_valid=True, bbox=[201.0, 218.0, 210.0, 257.0]), TextChar(polygon=[[207.0, 218.0], [227.0, 218.0], [227.0, 257.0], [207.0, 257.0]], confidence=0.9976497292518616, text='à¤¤', bbox_valid=True, bbox=[207.0, 218.0, 227.0, 257.0]), TextChar(polygon=[[206.0, 219.0], [227.0, 218.0], [227.0, 257.0], [206.0, 257.0]], confidence=0.9994279742240906, text='à¤¿', bbox_valid=True, bbox=[206.0, 218.0, 227.0, 257.0]), TextChar(polygon=[[225.0, 217.0], [248.0, 217.0], [248.0, 257.0], [225.0, 257.0]], confidence=0.9807953238487244, text='à¤¥', bbox_valid=True, bbox=[225.0, 217.0, 248.0, 257.0]), TextChar(polygon=[[224.0, 217.0], [247.0, 217.0], [247.0, 257.0], [224.0, 257.0]], confidence=0.9989620447158813, text='à¤¿', bbox_valid=True, bbox=[224.0, 217.0, 247.0, 257.0]), TextChar(polygon=[[244.0, 216.0], [255.0, 216.0], [255.0, 257.0], [244.0, 257.0]], confidence=0.9931667447090149, text='/', bbox_valid=True, bbox=[244.0, 216.0, 255.0, 257.0]), TextChar(polygon=[[253.0, 216.0], [261.0, 215.0], [261.0, 257.0], [253.0, 257.0]], confidence=0.9883307218551636, text=' ', bbox_valid=True, bbox=[253.0, 215.0, 261.0, 257.0]), TextChar(polygon=[[258.0, 215.0], [276.0, 215.0], [276.0, 257.0], [258.0, 257.0]], confidence=0.9985026121139526, text='D', bbox_valid=True, bbox=[258.0, 215.0, 276.0, 257.0]), TextChar(polygon=[[274.0, 214.0], [294.0, 214.0], [294.0, 256.0], [274.0, 257.0]], confidence=0.998955488204956, text='O', bbox_valid=True, bbox=[274.0, 214.0, 294.0, 257.0]), TextChar(polygon=[[293.0, 214.0], [310.0, 214.0], [310.0, 256.0], [293.0, 256.0]], confidence=0.9993127584457397, text='B', bbox_valid=True, bbox=[293.0, 214.0, 310.0, 256.0]), TextChar(polygon=[[305.0, 213.0], [315.0, 213.0], [315.0, 255.0], [305.0, 256.0]], confidence=0.9995840191841125, text=':', bbox_valid=True, bbox=[305.0, 213.0, 315.0, 256.0]), TextChar(polygon=[[312.0, 213.0], [320.0, 212.0], [320.0, 255.0], [312.0, 256.0]], confidence=0.9992989301681519, text=' ', bbox_valid=True, bbox=[312.0, 212.0, 320.0, 256.0]), TextChar(polygon=[[318.0, 212.0], [335.0, 212.0], [335.0, 254.0], [318.0, 254.0]], confidence=0.9986963868141174, text='0', bbox_valid=True, bbox=[318.0, 212.0, 335.0, 254.0]), TextChar(polygon=[[334.0, 211.0], [349.0, 211.0], [349.0, 254.0], [334.0, 254.0]], confidence=0.9999121427536011, text='1', bbox_valid=True, bbox=[334.0, 211.0, 349.0, 254.0]), TextChar(polygon=[[347.0, 210.0], [357.0, 210.0], [357.0, 254.0], [347.0, 254.0]], confidence=0.9998584985733032, text='/', bbox_valid=True, bbox=[347.0, 210.0, 357.0, 254.0]), TextChar(polygon=[[354.0, 210.0], [369.0, 210.0], [368.0, 253.0], [354.0, 254.0]], confidence=0.9999644756317139, text='0', bbox_valid=True, bbox=[354.0, 210.0, 369.0, 254.0]), TextChar(polygon=[[368.0, 209.0], [382.0, 209.0], [382.0, 253.0], [367.0, 253.0]], confidence=0.99986732006073, text='1', bbox_valid=True, bbox=[367.0, 209.0, 382.0, 253.0]), TextChar(polygon=[[381.0, 209.0], [391.0, 209.0], [390.0, 253.0], [380.0, 253.0]], confidence=0.9999489784240723, text='/', bbox_valid=True, bbox=[380.0, 209.0, 391.0, 253.0]), TextChar(polygon=[[389.0, 209.0], [403.0, 209.0], [402.0, 253.0], [388.0, 253.0]], confidence=0.9998396635055542, text='1', bbox_valid=True, bbox=[388.0, 209.0, 403.0, 253.0]), TextChar(polygon=[[399.0, 209.0], [414.0, 209.0], [414.0, 252.0], [399.0, 252.0]], confidence=0.9999369382858276, text='9', bbox_valid=True, bbox=[399.0, 209.0, 414.0, 252.0]), TextChar(polygon=[[412.0, 208.0], [427.0, 208.0], [426.0, 252.0], [411.0, 252.0]], confidence=0.9999566078186035, text='9', bbox_valid=True, bbox=[411.0, 208.0, 427.0, 252.0]), TextChar(polygon=[[425.0, 208.0], [439.0, 208.0], [438.0, 251.0], [424.0, 251.0]], confidence=0.9999014139175415, text='1', bbox_valid=True, bbox=[424.0, 208.0, 439.0, 251.0])], original_text_good=False, words=[], bbox=[159.0, 208.0, 447.0, 258.0]), TextLine(polygon=[[158.0, 270.0], [288.0, 263.0], [290.0, 296.0], [160.0, 303.0]], confidence=0.9658514300982157, text='à¤ªà¥à¤°à¥à¤· / MALE', chars=[TextChar(polygon=[[158.0, 263.0], [158.0, 264.0], [159.0, 264.0], [159.0, 263.0]], confidence=0.9401918649673462, text='', bbox_valid=False, bbox=[158.0, 263.0, 159.0, 264.0]), TextChar(polygon=[[158.0, 263.0], [158.0, 264.0], [159.0, 264.0], [159.0, 263.0]], confidence=0.8066011667251587, text='', bbox_valid=False, bbox=[158.0, 263.0, 159.0, 264.0]), TextChar(polygon=[[158.0, 263.0], [158.0, 264.0], [159.0, 264.0], [159.0, 263.0]], confidence=0.8752935528755188, text='', bbox_valid=False, bbox=[158.0, 263.0, 159.0, 264.0]), TextChar(polygon=[[170.0, 264.0], [183.0, 264.0], [183.0, 301.0], [170.0, 301.0]], confidence=0.929167628288269, text='à¤ª', bbox_valid=True, bbox=[170.0, 264.0, 183.0, 301.0]), TextChar(polygon=[[171.0, 264.0], [184.0, 264.0], [184.0, 301.0], [171.0, 301.0]], confidence=0.9882060289382935, text='à¥', bbox_valid=True, bbox=[171.0, 264.0, 184.0, 301.0]), TextChar(polygon=[[180.0, 264.0], [191.0, 263.0], [191.0, 301.0], [180.0, 301.0]], confidence=0.9994679093360901, text='à¤°', bbox_valid=True, bbox=[180.0, 263.0, 191.0, 301.0]), TextChar(polygon=[[180.0, 264.0], [194.0, 264.0], [194.0, 300.0], [180.0, 301.0]], confidence=0.9997968077659607, text='à¥', bbox_valid=True, bbox=[180.0, 264.0, 194.0, 301.0]), TextChar(polygon=[[190.0, 264.0], [203.0, 264.0], [203.0, 300.0], [190.0, 301.0]], confidence=0.9998002648353577, text='à¤·', bbox_valid=True, bbox=[190.0, 264.0, 203.0, 301.0]), TextChar(polygon=[[203.0, 264.0], [212.0, 264.0], [212.0, 300.0], [202.0, 300.0]], confidence=0.9926481246948242, text=' ', bbox_valid=True, bbox=[202.0, 264.0, 212.0, 300.0]), TextChar(polygon=[[208.0, 264.0], [220.0, 264.0], [220.0, 300.0], [208.0, 300.0]], confidence=0.9917005896568298, text='/', bbox_valid=True, bbox=[208.0, 264.0, 220.0, 300.0]), TextChar(polygon=[[214.0, 264.0], [221.0, 264.0], [221.0, 300.0], [214.0, 300.0]], confidence=0.9722787141799927, text=' ', bbox_valid=True, bbox=[214.0, 264.0, 221.0, 300.0]), TextChar(polygon=[[221.0, 264.0], [238.0, 264.0], [238.0, 300.0], [221.0, 300.0]], confidence=0.9930480122566223, text='M', bbox_valid=True, bbox=[221.0, 264.0, 238.0, 300.0]), TextChar(polygon=[[238.0, 264.0], [252.0, 264.0], [252.0, 300.0], [238.0, 300.0]], confidence=0.999840497970581, text='A', bbox_valid=True, bbox=[238.0, 264.0, 252.0, 300.0]), TextChar(polygon=[[249.0, 264.0], [262.0, 264.0], [261.0, 300.0], [249.0, 300.0]], confidence=0.9999088048934937, text='L', bbox_valid=True, bbox=[249.0, 264.0, 262.0, 300.0]), TextChar(polygon=[[256.0, 265.0], [269.0, 265.0], [269.0, 299.0], [256.0, 300.0]], confidence=0.9998214840888977, text='E', bbox_valid=True, bbox=[256.0, 265.0, 269.0, 300.0])], original_text_good=False, words=[], bbox=[158.0, 263.0, 290.0, 303.0]), TextLine(polygon=[[176.0, 432.0], [409.0, 417.0], [412.0, 457.0], [178.0, 472.0]], confidence=0.9962854743003845, text='6754 3973 8680', chars=[TextChar(polygon=[[176.0, 417.0], [176.0, 418.0], [177.0, 418.0], [177.0, 417.0]], confidence=0.9931279420852661, text='', bbox_valid=False, bbox=[176.0, 417.0, 177.0, 418.0]), TextChar(polygon=[[190.0, 427.0], [215.0, 427.0], [215.0, 469.0], [190.0, 469.0]], confidence=0.957194983959198, text='6', bbox_valid=True, bbox=[190.0, 427.0, 215.0, 469.0]), TextChar(polygon=[[203.0, 426.0], [223.0, 425.0], [223.0, 470.0], [203.0, 471.0]], confidence=0.9998175501823425, text='7', bbox_valid=True, bbox=[203.0, 425.0, 223.0, 471.0]), TextChar(polygon=[[218.0, 425.0], [237.0, 425.0], [236.0, 471.0], [217.0, 471.0]], confidence=0.9999736547470093, text='5', bbox_valid=True, bbox=[217.0, 425.0, 237.0, 471.0]), TextChar(polygon=[[234.0, 425.0], [253.0, 424.0], [253.0, 470.0], [234.0, 470.0]], confidence=0.9996740818023682, text='4', bbox_valid=True, bbox=[234.0, 424.0, 253.0, 470.0]), TextChar(polygon=[[251.0, 425.0], [263.0, 424.0], [263.0, 469.0], [250.0, 469.0]], confidence=0.9959576725959778, text=' ', bbox_valid=True, bbox=[250.0, 424.0, 263.0, 469.0]), TextChar(polygon=[[259.0, 424.0], [275.0, 424.0], [275.0, 469.0], [258.0, 469.0]], confidence=0.9996823072433472, text='3', bbox_valid=True, bbox=[258.0, 424.0, 275.0, 469.0]), TextChar(polygon=[[273.0, 423.0], [291.0, 423.0], [291.0, 469.0], [273.0, 469.0]], confidence=0.9999079704284668, text='9', bbox_valid=True, bbox=[273.0, 423.0, 291.0, 469.0]), TextChar(polygon=[[290.0, 422.0], [309.0, 422.0], [308.0, 468.0], [289.0, 469.0]], confidence=0.9999840259552002, text='7', bbox_valid=True, bbox=[289.0, 422.0, 309.0, 469.0]), TextChar(polygon=[[306.0, 421.0], [324.0, 421.0], [324.0, 468.0], [306.0, 469.0]], confidence=0.9999533891677856, text='3', bbox_valid=True, bbox=[306.0, 421.0, 324.0, 469.0]), TextChar(polygon=[[319.0, 421.0], [331.0, 420.0], [330.0, 467.0], [319.0, 467.0]], confidence=0.9993025064468384, text=' ', bbox_valid=True, bbox=[319.0, 420.0, 331.0, 467.0]), TextChar(polygon=[[326.0, 420.0], [345.0, 420.0], [345.0, 467.0], [326.0, 467.0]], confidence=0.9998806715011597, text='8', bbox_valid=True, bbox=[326.0, 420.0, 345.0, 467.0]), TextChar(polygon=[[342.0, 420.0], [361.0, 419.0], [361.0, 466.0], [342.0, 467.0]], confidence=0.9999345541000366, text='6', bbox_valid=True, bbox=[342.0, 419.0, 361.0, 467.0]), TextChar(polygon=[[360.0, 419.0], [378.0, 419.0], [378.0, 466.0], [359.0, 467.0]], confidence=0.9999502897262573, text='8', bbox_valid=True, bbox=[359.0, 419.0, 378.0, 467.0]), TextChar(polygon=[[371.0, 420.0], [390.0, 419.0], [389.0, 465.0], [370.0, 466.0]], confidence=0.9999405145645142, text='0', bbox_valid=True, bbox=[370.0, 419.0, 390.0, 466.0])], original_text_good=False, words=[], bbox=[176.0, 417.0, 412.0, 472.0]), TextLine(polygon=[[74.0, 496.0], [486.0, 461.0], [490.0, 519.0], [78.0, 554.0]], confidence=0.9996950393137725, text='à¤®à¥‡à¤°à¤¾ à¤†à¤§à¤¾à¤°, à¤®à¥‡à¤°à¥€ à¤ªà¤¹à¤šà¤¾à¤¨', chars=[TextChar(polygon=[[74.0, 461.0], [74.0, 462.0], [75.0, 462.0], [75.0, 461.0]], confidence=0.9992971420288086, text='', bbox_valid=False, bbox=[74.0, 461.0, 75.0, 462.0]), TextChar(polygon=[[74.0, 461.0], [74.0, 462.0], [75.0, 462.0], [75.0, 461.0]], confidence=0.9962446093559265, text='', bbox_valid=False, bbox=[74.0, 461.0, 75.0, 462.0]), TextChar(polygon=[[84.0, 484.0], [123.0, 483.0], [123.0, 552.0], [84.0, 553.0]], confidence=0.9995649456977844, text='à¤®', bbox_valid=True, bbox=[84.0, 483.0, 123.0, 553.0]), TextChar(polygon=[[81.0, 484.0], [120.0, 483.0], [120.0, 553.0], [81.0, 553.0]], confidence=0.9998641014099121, text='à¥‡', bbox_valid=True, bbox=[81.0, 483.0, 120.0, 553.0]), TextChar(polygon=[[115.0, 482.0], [153.0, 481.0], [153.0, 552.0], [115.0, 553.0]], confidence=0.9998942613601685, text='à¤°', bbox_valid=True, bbox=[115.0, 481.0, 153.0, 553.0]), TextChar(polygon=[[112.0, 482.0], [148.0, 482.0], [148.0, 552.0], [112.0, 553.0]], confidence=0.9999836683273315, text='à¤¾', bbox_valid=True, bbox=[112.0, 482.0, 148.0, 553.0]), TextChar(polygon=[[149.0, 481.0], [174.0, 480.0], [173.0, 551.0], [148.0, 552.0]], confidence=0.9999653100967407, text=' ', bbox_valid=True, bbox=[148.0, 480.0, 174.0, 552.0]), TextChar(polygon=[[167.0, 479.0], [216.0, 479.0], [215.0, 551.0], [166.0, 551.0]], confidence=0.9999295473098755, text='à¤†', bbox_valid=True, bbox=[166.0, 479.0, 216.0, 551.0]), TextChar(polygon=[[206.0, 478.0], [256.0, 477.0], [256.0, 549.0], [206.0, 550.0]], confidence=0.999996542930603, text='à¤§', bbox_valid=True, bbox=[206.0, 477.0, 256.0, 550.0]), TextChar(polygon=[[201.0, 477.0], [249.0, 476.0], [249.0, 550.0], [201.0, 551.0]], confidence=0.999963641166687, text='à¤¾', bbox_valid=True, bbox=[201.0, 476.0, 249.0, 551.0]), TextChar(polygon=[[243.0, 475.0], [265.0, 474.0], [265.0, 548.0], [243.0, 549.0]], confidence=0.9999685287475586, text='à¤°', bbox_valid=True, bbox=[243.0, 474.0, 265.0, 549.0]), TextChar(polygon=[[261.0, 474.0], [276.0, 474.0], [276.0, 547.0], [261.0, 548.0]], confidence=0.9998047947883606, text=',', bbox_valid=True, bbox=[261.0, 474.0, 276.0, 548.0]), TextChar(polygon=[[270.0, 475.0], [295.0, 474.0], [294.0, 547.0], [269.0, 548.0]], confidence=0.9999470710754395, text=' ', bbox_valid=True, bbox=[269.0, 474.0, 295.0, 548.0]), TextChar(polygon=[[290.0, 474.0], [324.0, 473.0], [324.0, 547.0], [290.0, 548.0]], confidence=0.999910831451416, text='à¤®', bbox_valid=True, bbox=[290.0, 473.0, 324.0, 548.0]), TextChar(polygon=[[285.0, 474.0], [319.0, 473.0], [319.0, 547.0], [285.0, 548.0]], confidence=0.9999560117721558, text='à¥‡', bbox_valid=True, bbox=[285.0, 473.0, 319.0, 548.0]), TextChar(polygon=[[315.0, 472.0], [353.0, 471.0], [353.0, 545.0], [315.0, 546.0]], confidence=0.9999610185623169, text='à¤°', bbox_valid=True, bbox=[315.0, 471.0, 353.0, 546.0]), TextChar(polygon=[[315.0, 471.0], [348.0, 470.0], [348.0, 545.0], [315.0, 546.0]], confidence=0.9999854564666748, text='à¥€', bbox_valid=True, bbox=[315.0, 470.0, 348.0, 546.0]), TextChar(polygon=[[340.0, 472.0], [366.0, 471.0], [365.0, 545.0], [339.0, 545.0]], confidence=0.9999492168426514, text=' ', bbox_valid=True, bbox=[339.0, 471.0, 366.0, 545.0]), TextChar(polygon=[[364.0, 470.0], [391.0, 469.0], [390.0, 544.0], [363.0, 545.0]], confidence=0.9999663829803467, text='à¤ª', bbox_valid=True, bbox=[363.0, 469.0, 391.0, 545.0]), TextChar(polygon=[[381.0, 470.0], [410.0, 469.0], [410.0, 543.0], [381.0, 544.0]], confidence=0.9999741315841675, text='à¤¹', bbox_valid=True, bbox=[381.0, 469.0, 410.0, 544.0]), TextChar(polygon=[[395.0, 469.0], [445.0, 469.0], [444.0, 541.0], [394.0, 542.0]], confidence=0.9989213943481445, text='à¤š', bbox_valid=True, bbox=[394.0, 469.0, 445.0, 542.0]), TextChar(polygon=[[398.0, 466.0], [448.0, 465.0], [447.0, 541.0], [397.0, 542.0]], confidence=0.9999845027923584, text='à¤¾', bbox_valid=True, bbox=[397.0, 465.0, 448.0, 542.0]), TextChar(polygon=[[439.0, 465.0], [471.0, 464.0], [470.0, 540.0], [438.0, 540.0]], confidence=0.9999527931213379, text='à¤¨', bbox_valid=True, bbox=[438.0, 464.0, 471.0, 540.0])], original_text_good=False, words=[], bbox=[74.0, 461.0, 490.0, 554.0])], image_bbox=[0.0, 0.0, 640.0, 640.0])]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fff90f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# from transformers import pipeline\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# from PIL import Image\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# from surya.foundation import FoundationPredictor\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Extract text from predictions\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m ocr_text = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[43mpred\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predictions[\u001b[32m0\u001b[39m]])\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- OCR Output ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, ocr_text)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Run NER\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# # from transformers import pipeline\n",
    "# # from PIL import Image\n",
    "# # from surya.foundation import FoundationPredictor\n",
    "# # from surya.recognition import RecognitionPredictor\n",
    "# # from surya.detection import DetectionPredictor\n",
    "\n",
    "# # # --------------------------\n",
    "# # # Load Surya OCR\n",
    "# # # --------------------------\n",
    "# # image_path = \"aadhaar_sample.jpg\"\n",
    "# # image = Image.open(image_path)\n",
    "\n",
    "# # foundation_predictor = FoundationPredictor()\n",
    "# # recognition_predictor = RecognitionPredictor(foundation_predictor)\n",
    "# # detection_predictor = DetectionPredictor()\n",
    "\n",
    "# # predictions = recognition_predictor([image], det_predictor=detection_predictor)\n",
    "\n",
    "# # --------------------------\n",
    "# # Extract text from predictions\n",
    "# # --------------------------\n",
    "# ocr_text = \" \".join([pred.text for pred in predictions[0]])\n",
    "# print(\"\\n--- OCR Output ---\\n\", ocr_text)\n",
    "\n",
    "# # --------------------------\n",
    "# # Run NER\n",
    "# # --------------------------\n",
    "# ner = pipeline(\"ner\", model=\"Davlan/xlm-roberta-base-ner-hrl\", grouped_entities=True)\n",
    "# entities = ner(ocr_text)\n",
    "\n",
    "# print(\"\\n--- Extracted Entities ---\")\n",
    "# for ent in entities:\n",
    "#     print(f\"{ent['entity_group']}: {ent['word']} (score: {ent['score']:.2f})\")\n",
    "\n",
    "# # --------------------------\n",
    "# # Map to Aadhaar fields\n",
    "# # --------------------------\n",
    "# aadhaar_data = {\n",
    "#     \"name\": None,\n",
    "#     \"dob\": None,\n",
    "#     \"aadhaar_number\": None,\n",
    "#     \"gender\": None\n",
    "# }\n",
    "\n",
    "# for ent in entities:\n",
    "#     if ent[\"entity_group\"] in [\"PER\"]:\n",
    "#         aadhaar_data[\"name\"] = ent[\"word\"]\n",
    "#     elif ent[\"entity_group\"] in [\"DATE\"]:\n",
    "#         aadhaar_data[\"dob\"] = ent[\"word\"]\n",
    "#     elif ent[\"entity_group\"] in [\"ORG\"]:\n",
    "#         pass  # government issuer, skip for now\n",
    "\n",
    "# # Aadhaar number: 12-digit pattern, not NER\n",
    "# import re\n",
    "# aadhaar_match = re.search(r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\", ocr_text)\n",
    "# if aadhaar_match:\n",
    "#     aadhaar_data[\"aadhaar_number\"] = aadhaar_match.group()\n",
    "\n",
    "# # Gender heuristic\n",
    "# if \"male\" in ocr_text.lower():\n",
    "#     aadhaar_data[\"gender\"] = \"Male\"\n",
    "# elif \"female\" in ocr_text.lower():\n",
    "#     aadhaar_data[\"gender\"] = \"Female\"\n",
    "\n",
    "# print(\"\\n--- Structured Aadhaar Data ---\")\n",
    "# print(aadhaar_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce649e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'copy', 'dict', 'from_orm', 'image_bbox', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'text_lines', 'update_forward_refs', 'validate']\n"
     ]
    }
   ],
   "source": [
    "# print(dir(predictions[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3cf8260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- OCR Output ---\n",
      " à¤­à¤¾à¤°à¤¤ à¤¸à¤°à¤•à¤¾à¤° Government of India à¤°à¤¿à¤¯à¤¾à¤¸à¤¤ Riyasat à¤œà¤¨à¥à¤® à¤¤à¤¿à¤¥à¤¿/ DOB: 01/01/1991 à¤ªà¥à¤°à¥à¤· / MALE 6754 3973 8680 à¤®à¥‡à¤°à¤¾ à¤†à¤§à¤¾à¤°, à¤®à¥‡à¤°à¥€ à¤ªà¤¹à¤šà¤¾à¤¨\n"
     ]
    }
   ],
   "source": [
    "# Extract all text lines from OCR result\n",
    "ocr_text = \" \".join([line.text for line in predictions[0].text_lines])\n",
    "print(\"\\n--- OCR Output ---\\n\", ocr_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e903b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 0 files: 0it [00:00, ?it/s]\n",
      "Fetching 1 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<?, ?it/s]\n",
      "Fetching 0 files: 0it [00:00, ?it/s]\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extracted Aadhaar Fields ---\n",
      "{'Name': 'à¤®à¥‡à¤°à¥€ à¤ªà¤¹à¤šà¤¾à¤¨', 'DOB': '1991', 'Gender': 'à¤­à¤¾à¤°à¤¤ à¤¸à¤°à¤•à¤¾à¤° Government of India', 'AadhaarNumber': '8680'}\n"
     ]
    }
   ],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# ocr_text = \"\"\"à¤­à¤¾à¤°à¤¤ à¤¸à¤°à¤•à¤¾à¤° Government of India à¤°à¤¿à¤¯à¤¾à¤¸à¤¤ Riyasat à¤œà¤¨à¥à¤® à¤¤à¤¿à¤¥à¤¿/ DOB: 01/01/1991 à¤ªà¥à¤°à¥à¤· / MALE 6754 3973 8680 à¤®à¥‡à¤°à¤¾ à¤†à¤§à¤¾à¤°, à¤®à¥‡à¤°à¥€ à¤ªà¤¹à¤šà¤¾à¤¨\"\"\"\n",
    "# # ocr_text=ocr_text\n",
    "\n",
    "# # Load QA pipeline\n",
    "# qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "# queries = {\n",
    "#     \"Name\": \"What is the name on the Aadhaar card?\",\n",
    "#     \"DOB\": \"What is the date of birth?\",\n",
    "#     \"Gender\": \"What is the gender?\",\n",
    "#     \"AadhaarNumber\": \"What is the Aadhaar number?\"\n",
    "# }\n",
    "\n",
    "# extracted = {}\n",
    "# for field, question in queries.items():\n",
    "#     ans = qa_pipeline(question=question, context=ocr_text)\n",
    "#     extracted[field] = ans[\"answer\"]\n",
    "\n",
    "# print(\"\\n--- Extracted Aadhaar Fields ---\")\n",
    "# print(extracted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15803961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extracted Aadhaar Fields ---\n",
      "{'Name': None, 'DOB': '01/01/1991', 'Gender': 'à¤ªà¥à¤°à¥à¤·', 'AadhaarNumber': '6754 3973 8680'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import pipeline\n",
    "\n",
    "ocr_text = ocr_text\n",
    "\n",
    "# Step 1: NER model (to detect potential names, orgs, etc.)\n",
    "ner = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
    "ner_results = ner(ocr_text)\n",
    "\n",
    "# Step 2: Regex rules for Aadhaar-specific fields\n",
    "dob_pattern = re.search(r\"(\\d{2}/\\d{2}/\\d{4})\", ocr_text)\n",
    "gender_pattern = re.search(r\"\\b(MALE|FEMALE|à¤ªà¥à¤°à¥à¤·|à¤®à¤¹à¤¿à¤²à¤¾)\\b\", ocr_text, re.IGNORECASE)\n",
    "aadhaar_pattern = re.search(r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\", ocr_text)\n",
    "\n",
    "# Step 3: Extract Name (heuristic: first \"PER\" entity if available)\n",
    "name = None\n",
    "for ent in ner_results:\n",
    "    if ent[\"entity_group\"] == \"PER\":\n",
    "        name = ent[\"word\"]\n",
    "        break\n",
    "\n",
    "# Step 4: Final structured output\n",
    "extracted = {\n",
    "    \"Name\": name,\n",
    "    \"DOB\": dob_pattern.group(1) if dob_pattern else None,\n",
    "    \"Gender\": gender_pattern.group(1) if gender_pattern else None,\n",
    "    \"AadhaarNumber\": aadhaar_pattern.group(0) if aadhaar_pattern else None\n",
    "}\n",
    "\n",
    "print(\"\\n--- Extracted Aadhaar Fields ---\")\n",
    "print(extracted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299e3999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: surya-ocr in c:\\users\\siva_\\anaconda3\\lib\\site-packages (0.17.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.8 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (8.3.0)\n",
      "Requirement already satisfied: einops<0.9.0,>=0.8.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (0.8.1)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (1.2.0)\n",
      "Requirement already satisfied: opencv-python-headless==4.11.0.86 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (4.11.0.86)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.2.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (10.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.6 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (4.5.0)\n",
      "Requirement already satisfied: pre-commit<5.0.0,>=4.2.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (4.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (2.11.3)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.1.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (2.9.1)\n",
      "Requirement already satisfied: pypdfium2==4.30.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (4.30.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (1.1.0)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.7.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (2.9.0)\n",
      "Requirement already satisfied: transformers>=4.56.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from surya-ocr) (4.57.1)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from opencv-python-headless==4.11.0.86->surya-ocr) (1.26.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from click<9.0.0,>=8.1.8->surya-ocr) (0.4.6)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (2.6.15)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (1.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (6.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pre-commit<5.0.0,>=4.2.0->surya-ocr) (20.26.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.3->surya-ocr) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.3->surya-ocr) (2.33.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.3->surya-ocr) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.3->surya-ocr) (0.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.7.0->surya-ocr) (3.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.7.0->surya-ocr) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.7.0->surya-ocr) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.7.0->surya-ocr) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch<3.0.0,>=2.7.0->surya-ocr) (2025.3.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (2.29.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers>=4.56.1->surya-ocr) (4.65.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch<3.0.0,>=2.7.0->surya-ocr) (1.2.1)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit<5.0.0,>=4.2.0->surya-ocr) (0.3.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from jinja2->torch<3.0.0,>=2.7.0->surya-ocr) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers>=4.56.1->surya-ocr) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers>=4.56.1->surya-ocr) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers>=4.56.1->surya-ocr) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers>=4.56.1->surya-ocr) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "pip install surya-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48cbd7d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surya.ocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mocr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_ocr\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… surya imported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surya.ocr'"
     ]
    }
   ],
   "source": [
    "from surya.ocr import run_ocr\n",
    "print(\"âœ… surya imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e4299a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PreTrainedModel' from 'transformers' (c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… PreTrainedModel import works!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'PreTrainedModel' from 'transformers' (c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# from transformers import PreTrainedModel\n",
    "# print(\"âœ… PreTrainedModel import works!\")\n",
    "\n",
    "# from surya.ocr import run_ocr\n",
    "# print(\"âœ… surya OCR import works!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22864d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.57.1\n",
      "Surya location: c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\surya\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "\n",
    "import surya\n",
    "print(\"Surya location:\", surya.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ba16b34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PreTrainedModel' from 'transformers' (c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfoundation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FoundationPredictor\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecognition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecognitionPredictor\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DetectionPredictor\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\surya\\foundation\\__init__.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurya\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SuryaModelOutput\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxla\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mark_step\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasePredictor\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\surya\\common\\surya\\__init__.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cache\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttentionMaskConverter\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrained\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SuryaPreTrainedModel\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01ms3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m S3DownloaderMixin\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SuryaModelConfig\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\surya\\common\\pretrained.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_flash_attn_2_available\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSuryaPreTrainedModel\u001b[39;00m(PreTrainedModel):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# No-op if we pass attention, so we can set attention however we want in the config\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'PreTrainedModel' from 'transformers' (c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from surya.foundation import FoundationPredictor\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor\n",
    "\n",
    "image = Image.open(image_path)\n",
    "foundation_predictor = FoundationPredictor()\n",
    "recognition_predictor = RecognitionPredictor(foundation_predictor)\n",
    "detection_predictor = DetectionPredictor()\n",
    "\n",
    "predictions = recognition_predictor([image], det_predictor=detection_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73aaacb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PreTrainedModel' from 'transformers' (c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… transformers OK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'PreTrainedModel' from 'transformers' (c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedModel\n",
    "print(\"âœ… transformers OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d29293c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Could not import module 'PreTrainedModel'. Are this object's requirements defined correctly?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2317\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   2318\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1149\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:70\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     62\u001b[0m     _get_parameter_tp_plan,\n\u001b[0;32m     63\u001b[0m     distribute_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     verify_tp_plan,\n\u001b[0;32m     69\u001b[0m )\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LOSS_MAPPING\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_flash_attention_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lazy_import_flash_attention\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\loss\\loss_utils.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss, MSELoss\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_d_fine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DFineForObjectDetectionLoss\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_deformable_detr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\loss\\loss_d_fine.py:21\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_vision_available\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_for_object_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     box_iou,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_rt_detr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDetrHungarianMatcher, RTDetrLoss\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\loss\\loss_for_object_detection.py:32\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_vision_available():\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_to_corners_format\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdice_loss\u001b[39m(inputs, targets, num_boxes):\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\image_transforms.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     ChannelDimension,\n\u001b[0;32m     24\u001b[0m     ImageInput,\n\u001b[0;32m     25\u001b[0m     get_channel_dimension_axis,\n\u001b[0;32m     26\u001b[0m     get_image_size,\n\u001b[0;32m     27\u001b[0m     infer_channel_dimension_format,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\image_utils.py:55\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torchvision_available():\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n\u001b[0;32m     57\u001b[0m     pil_torch_interpolation_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     58\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mNEAREST: InterpolationMode\u001b[38;5;241m.\u001b[39mNEAREST_EXACT,\n\u001b[0;32m     59\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mBOX: InterpolationMode\u001b[38;5;241m.\u001b[39mBOX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mLANCZOS: InterpolationMode\u001b[38;5;241m.\u001b[39mLANCZOS,\n\u001b[0;32m     64\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torchvision\\__init__.py:10\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torchvision\\_meta_registrations.py:163\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mnew_empty((batch_size, channels, height, width))\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mlibrary\u001b[38;5;241m.\u001b[39mregister_fake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchvision::nms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeta_nms\u001b[39m(dets, scores, iou_threshold):\n\u001b[0;32m    165\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_check(dets\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes should be a 2d tensor, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdets\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torch\\library.py:1063\u001b[0m, in \u001b[0;36mregister_fake.<locals>.register\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m   1062\u001b[0m     use_lib \u001b[38;5;241m=\u001b[39m lib\n\u001b[1;32m-> 1063\u001b[0m use_lib\u001b[38;5;241m.\u001b[39m_register_fake(\n\u001b[0;32m   1064\u001b[0m     op_name, func, _stacklevel\u001b[38;5;241m=\u001b[39mstacklevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, allow_override\u001b[38;5;241m=\u001b[39mallow_override\n\u001b[0;32m   1065\u001b[0m )\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torch\\library.py:211\u001b[0m, in \u001b[0;36mLibrary._register_fake\u001b[1;34m(self, op_name, fn, _stacklevel, allow_override)\u001b[0m\n\u001b[0;32m    209\u001b[0m     func_to_register \u001b[38;5;241m=\u001b[39m fn\n\u001b[1;32m--> 211\u001b[0m handle \u001b[38;5;241m=\u001b[39m entry\u001b[38;5;241m.\u001b[39mfake_impl\u001b[38;5;241m.\u001b[39mregister(\n\u001b[0;32m    212\u001b[0m     func_to_register, source, lib\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, allow_override\u001b[38;5;241m=\u001b[39mallow_override\n\u001b[0;32m    213\u001b[0m )\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registration_handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\torch\\_library\\fake_impl.py:50\u001b[0m, in \u001b[0;36mFakeImplHolder.register\u001b[1;34m(self, func, source, lib, allow_override)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an fake impl registered at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     49\u001b[0m     )\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dispatch_has_kernel_for_dispatch_key(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeta\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an DispatchKey::Meta implementation via a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: operator torchvision::nms does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfoundation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FoundationPredictor\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecognition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecognitionPredictor\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DetectionPredictor\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\surya\\foundation\\__init__.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurya\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SuryaModelOutput\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxla\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mark_step\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasePredictor\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\surya\\common\\surya\\__init__.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cache\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttentionMaskConverter\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrained\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SuryaPreTrainedModel\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01ms3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m S3DownloaderMixin\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SuryaModelConfig\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\surya\\common\\pretrained.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_flash_attn_2_available\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSuryaPreTrainedModel\u001b[39;00m(PreTrainedModel):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# No-op if we pass attention, so we can set attention however we want in the config\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2320\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2320\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m   2321\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Are this object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms requirements defined correctly?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2322\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m   2325\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: Could not import module 'PreTrainedModel'. Are this object's requirements defined correctly?"
     ]
    }
   ],
   "source": [
    "from surya.foundation import FoundationPredictor\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ff1739a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "                                              0.0/12.0 MB ? eta -:--:--\n",
      "     -                                        0.6/12.0 MB 17.3 MB/s eta 0:00:01\n",
      "     -----                                    1.8/12.0 MB 22.7 MB/s eta 0:00:01\n",
      "     -----------                              3.5/12.0 MB 27.6 MB/s eta 0:00:01\n",
      "     -----------------                        5.2/12.0 MB 30.3 MB/s eta 0:00:01\n",
      "     -----------------------                  6.9/12.0 MB 31.6 MB/s eta 0:00:01\n",
      "     ----------------------------             8.5/12.0 MB 31.8 MB/s eta 0:00:01\n",
      "     --------------------------------        10.0/12.0 MB 33.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  11.8/12.0 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.0/12.0 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.0/12.0 MB 28.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "                                              0.0/2.7 MB ? eta -:--:--\n",
      "     --------------------                     1.4/2.7 MB 28.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 28.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.7/2.7 MB 28.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (4.65.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.10.5)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "Successfully installed tokenizers-0.22.1 transformers-4.57.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lmdeploy 0.7.2.post1 requires torch<=2.5.1,>=2.0.0, but you have torch 2.9.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e748e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.57.1\n",
      "Uninstalling transformers-4.57.1:\n",
      "  Successfully uninstalled transformers-4.57.1\n",
      "Found existing installation: tokenizers 0.22.1\n",
      "Uninstalling tokenizers-0.22.1:\n",
      "  Successfully uninstalled tokenizers-0.22.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 169, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\pip\\_internal\\commands\\uninstall.py\", line 110, in run\n",
      "    uninstall_pathset.commit()\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py\", line 432, in commit\n",
      "    self._moved_paths.commit()\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py\", line 278, in commit\n",
      "    save_dir.cleanup()\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 173, in cleanup\n",
      "    rmtree(self._path)\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 291, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 381, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 327, in iter\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 160, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 384, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 130, in rmtree\n",
      "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\shutil.py\", line 759, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\shutil.py\", line 622, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"c:\\Users\\siva_\\anaconda3\\Lib\\shutil.py\", line 620, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\siva_\\\\anaconda3\\\\Lib\\\\site-packages\\\\~okenizers\\\\tokenizers.pyd'\n"
     ]
    }
   ],
   "source": [
    "pip uninstall transformers tokenizers accelerate -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c50bc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.43.3\n",
      "  Downloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
      "                                              0.0/9.4 MB ? eta -:--:--\n",
      "                                              0.0/9.4 MB ? eta -:--:--\n",
      "                                              0.0/9.4 MB ? eta -:--:--\n",
      "                                              0.0/9.4 MB 163.8 kB/s eta 0:00:58\n",
      "                                              0.0/9.4 MB 163.8 kB/s eta 0:00:58\n",
      "                                              0.0/9.4 MB 163.8 kB/s eta 0:00:58\n",
      "                                              0.1/9.4 MB 192.5 kB/s eta 0:00:49\n",
      "                                              0.1/9.4 MB 241.3 kB/s eta 0:00:39\n",
      "                                              0.1/9.4 MB 284.4 kB/s eta 0:00:33\n",
      "                                              0.1/9.4 MB 288.1 kB/s eta 0:00:33\n",
      "                                              0.2/9.4 MB 338.3 kB/s eta 0:00:28\n",
      "                                              0.2/9.4 MB 401.2 kB/s eta 0:00:23\n",
      "     -                                        0.3/9.4 MB 462.0 kB/s eta 0:00:20\n",
      "     -                                        0.3/9.4 MB 512.9 kB/s eta 0:00:18\n",
      "     -                                        0.4/9.4 MB 559.1 kB/s eta 0:00:17\n",
      "     -                                        0.5/9.4 MB 655.2 kB/s eta 0:00:14\n",
      "     --                                       0.6/9.4 MB 766.3 kB/s eta 0:00:12\n",
      "     --                                       0.7/9.4 MB 864.2 kB/s eta 0:00:11\n",
      "     ---                                      0.8/9.4 MB 932.1 kB/s eta 0:00:10\n",
      "     ----                                     1.0/9.4 MB 1.1 MB/s eta 0:00:08\n",
      "     ----                                     1.1/9.4 MB 1.2 MB/s eta 0:00:07\n",
      "     -----                                    1.3/9.4 MB 1.4 MB/s eta 0:00:06\n",
      "     ------                                   1.5/9.4 MB 1.5 MB/s eta 0:00:06\n",
      "     -------                                  1.8/9.4 MB 1.7 MB/s eta 0:00:05\n",
      "     ---------                                2.2/9.4 MB 2.0 MB/s eta 0:00:04\n",
      "     ----------                               2.5/9.4 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------                             2.9/9.4 MB 2.4 MB/s eta 0:00:03\n",
      "     -------------                            3.3/9.4 MB 2.6 MB/s eta 0:00:03\n",
      "     ----------------                         3.8/9.4 MB 3.0 MB/s eta 0:00:02\n",
      "     --------------------                     4.8/9.4 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------------                   5.4/9.4 MB 3.9 MB/s eta 0:00:02\n",
      "     ------------------------                 5.8/9.4 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------              6.4/9.4 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------           7.1/9.4 MB 4.7 MB/s eta 0:00:01\n",
      "     ---------------------------------        7.9/9.4 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------     8.5/9.4 MB 5.3 MB/s eta 0:00:01\n",
      "     --------------------------------------   9.2/9.4 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.4/9.4 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 9.4/9.4 MB 5.5 MB/s eta 0:00:00\n",
      "Collecting tokenizers==0.15.2\n",
      "  Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl (2.2 MB)\n",
      "                                              0.0/2.2 MB ? eta -:--:--\n",
      "     -------------                            0.7/2.2 MB 23.8 MB/s eta 0:00:01\n",
      "     ----------------------------             1.6/2.2 MB 20.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.2/2.2 MB 17.5 MB/s eta 0:00:00\n",
      "Collecting accelerate==0.28.0\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "                                              0.0/290.1 kB ? eta -:--:--\n",
      "     ------------------------------------- 290.1/290.1 kB 17.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers==4.43.3) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers==4.43.3) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers==4.43.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers==4.43.3) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers==4.43.3) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers==4.43.3) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers==4.43.3) (2.29.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers==4.43.3) (0.5.3)\n",
      "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "\n",
      "The conflict is caused by:\n",
      "    The user requested tokenizers==0.15.2\n",
      "    transformers 4.43.3 depends on tokenizers<0.20 and >=0.19\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install tokenizers==0.15.2 and transformers==4.43.3 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.43.3 tokenizers==0.15.2 accelerate==0.28.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74d84e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Could not import module 'PreTrainedModel'. Are this object's requirements defined correctly?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2317\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   2318\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1142\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers.modeling_utils'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfoundation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FoundationPredictor\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\surya\\foundation\\__init__.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurya\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SuryaModelOutput\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxla\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mark_step\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasePredictor\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\surya\\common\\surya\\__init__.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cache\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttentionMaskConverter\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrained\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SuryaPreTrainedModel\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01ms3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m S3DownloaderMixin\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurya\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SuryaModelConfig\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\surya\\common\\pretrained.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_flash_attn_2_available\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSuryaPreTrainedModel\u001b[39;00m(PreTrainedModel):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# No-op if we pass attention, so we can set attention however we want in the config\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siva_\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2320\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2320\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m   2321\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Are this object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms requirements defined correctly?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2322\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m   2325\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: Could not import module 'PreTrainedModel'. Are this object's requirements defined correctly?"
     ]
    }
   ],
   "source": [
    "from surya.foundation import FoundationPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c2b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall transformers tokenizers accelerate -y\n",
    "pip install transformers==4.43.3 tokenizers==0.15.2 accelerate==0.28.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a65668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\siva_\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\siva_\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\siva_\\anaconda3\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\siva_\\anaconda3\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\siva_\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\siva_\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: filelock in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from transformers) (4.65.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siva_\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision pillow transformers sentencepiece opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c98931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall surya-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3665928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extracted Aadhaar Fields ---\n",
      "{'Name': 'Riyasat', 'DOB': '01/01/1991', 'Gender': 'MALE', 'AadhaarNumber': '6754 3973 8680'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import pipeline\n",
    "\n",
    "ocr_text = ocr_text\n",
    "\n",
    "# Step 1: Run NER\n",
    "ner = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
    "ner_results = ner(ocr_text)\n",
    "\n",
    "# Step 2: Extract Name (NER first, else regex fallback)\n",
    "name = None\n",
    "for ent in ner_results:\n",
    "    if ent[\"entity_group\"] == \"PER\":\n",
    "        name = ent[\"word\"]\n",
    "        break\n",
    "\n",
    "if not name:\n",
    "    # fallback: capture text before DOB / à¤œà¤¨à¥à¤® à¤¤à¤¿à¤¥à¤¿\n",
    "    match = re.search(r\"(.*?)\\s+(?:à¤œà¤¨à¥à¤® à¤¤à¤¿à¤¥à¤¿|DOB)\", ocr_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        # take last word/phrase before DOB\n",
    "        possible_name = match.group(1).strip().split()[-1]\n",
    "        name = possible_name\n",
    "\n",
    "# Step 3: Extract DOB\n",
    "dob_pattern = re.search(r\"\\b\\d{2}/\\d{2}/\\d{4}\\b\", ocr_text)\n",
    "\n",
    "# Step 4: Extract Gender (prefer English if both exist)\n",
    "gender_match = re.findall(r\"\\b(MALE|FEMALE|à¤ªà¥à¤°à¥à¤·|à¤®à¤¹à¤¿à¤²à¤¾)\\b\", ocr_text, re.IGNORECASE)\n",
    "gender = None\n",
    "if gender_match:\n",
    "    # prefer English version if present\n",
    "    for g in gender_match:\n",
    "        if g.upper() in [\"MALE\", \"FEMALE\"]:\n",
    "            gender = g.upper()\n",
    "            break\n",
    "    if not gender:  # fallback to Hindi\n",
    "        gender = gender_match[0]\n",
    "\n",
    "# Step 5: Extract Aadhaar number\n",
    "aadhaar_pattern = re.search(r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\", ocr_text)\n",
    "\n",
    "# Step 6: Final structured output\n",
    "extracted = {\n",
    "    \"Name\": name,\n",
    "    \"DOB\": dob_pattern.group(0) if dob_pattern else None,\n",
    "    \"Gender\": gender,\n",
    "    \"AadhaarNumber\": aadhaar_pattern.group(0) if aadhaar_pattern else None\n",
    "}\n",
    "\n",
    "print(\"\\n--- Extracted Aadhaar Fields ---\")\n",
    "print(extracted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f621f349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Riyasat', 'DOB': '01/01/1991', 'Gender': 'MALE', 'AadhaarNumber': '6754 3973 8680'}\n"
     ]
    }
   ],
   "source": [
    "print(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b31516",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RealDictCursor\n\u001b[32m      4\u001b[39m DB_CONFIG = {\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdbname\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mkyc_db\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33muser\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mpostgres\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mport\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m5432\u001b[39m\n\u001b[32m     10\u001b[39m }\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'kyc_db',\n",
    "    'user': 'postgres',\n",
    "    'password': 'root',\n",
    "    'host': 'localhost',\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "def verify_aadhaar_record(ocr_result):\n",
    "    \"\"\"\n",
    "    Verify OCR extracted Aadhaar details against aadhaar_holders table.\n",
    "    \n",
    "    Args:\n",
    "        ocr_result (dict): Extracted fields with keys: 'Name', 'DOB', 'Gender', 'AadhaarNumber'\n",
    "    \n",
    "    Returns:\n",
    "        str: 'Yes' if exact match found, 'No' otherwise.\n",
    "    \"\"\"\n",
    "    name = ocr_result.get('Name', '').strip()\n",
    "    dob_str = ocr_result.get('DOB', '').strip()\n",
    "    gender = ocr_result.get('Gender', '').capitalize()  # Make sure casing matches DB (Male, Female, Transgender)\n",
    "    aadhaar_number_raw = ocr_result.get('AadhaarNumber', '').replace(' ', '')\n",
    "    \n",
    "    # Convert DOB from dd/mm/yyyy to yyyy-mm-dd for date comparison\n",
    "    try:\n",
    "        dob_parts = dob_str.split('/')\n",
    "        dob_formatted = f\"{dob_parts[2]}-{dob_parts[1]}-{dob_parts[0]}\"\n",
    "    except Exception:\n",
    "        return \"No\"  # Invalid date format, treat as no match\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT 1 FROM aadhaar_holders\n",
    "    WHERE aadhaar_number = %s AND full_name = %s AND date_of_birth = %s AND gender = %s\n",
    "    LIMIT 1;\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query, (aadhaar_number_raw, name, dob_formatted, gender))\n",
    "        result = cursor.fetchone()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        if result:\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "    except Exception as e:\n",
    "        # You may log the error or handle it accordingly\n",
    "        print(f\"DB Error: {e}\")\n",
    "        return \"No\"\n",
    "\n",
    "# Example usage:\n",
    "ocr_extracted = {'Name': 'Riyasat', 'DOB': '01/01/1991', 'Gender': 'MALE', 'AadhaarNumber': '6754 3973 8680'}\n",
    "status = verify_aadhaar_record(ocr_extracted)\n",
    "print(status)  # Outputs: 'Yes' or 'No'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99212eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification status: Yes\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'kyc_db',\n",
    "    'user': 'postgres',\n",
    "    'password': 'root',\n",
    "    'host': 'localhost',\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "def verify_aadhaar_record(ocr_result):\n",
    "    \"\"\"\n",
    "    Verify OCR extracted Aadhaar details against aadhaar_holders table.\n",
    "\n",
    "    Args:\n",
    "        ocr_result (dict): Extracted fields with keys: 'Name', 'DOB', 'Gender', 'AadhaarNumber'\n",
    "\n",
    "    Returns:\n",
    "        str: 'Yes' if exact match found, 'No' otherwise.\n",
    "    \"\"\"\n",
    "    name = ocr_result.get('Name', '').strip()\n",
    "    dob_str = ocr_result.get('DOB', '').strip()\n",
    "    gender = ocr_result.get('Gender', '').capitalize()  # Adjust to match DB format (Male, Female, Transgender)\n",
    "    aadhaar_number_raw = ocr_result.get('AadhaarNumber', '').replace(' ', '')\n",
    "\n",
    "    # Convert DOB from dd/mm/yyyy to yyyy-mm-dd for date comparison\n",
    "    try:\n",
    "        dob_parts = dob_str.split('/')\n",
    "        dob_formatted = f\"{dob_parts[2]}-{dob_parts[1]}-{dob_parts[0]}\"\n",
    "    except Exception:\n",
    "        # Invalid date format; consider it no match\n",
    "        return \"No\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT 1 FROM aadhaar_holders\n",
    "    WHERE aadhaar_number = %s AND full_name = %s AND date_of_birth = %s AND gender = %s\n",
    "    LIMIT 1;\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(query, (aadhaar_number_raw, name, dob_formatted, gender))\n",
    "                result = cursor.fetchone()\n",
    "\n",
    "        return \"Yes\" if result else \"No\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        return \"No\"\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    ocr_extracted=extracted\n",
    "    # ocr_extracted = {\n",
    "    #     'Name': 'Riyasat',\n",
    "    #     'DOB': '01/01/1991',\n",
    "    #     'Gender': 'MALE',\n",
    "    #     'AadhaarNumber': '6754 3973 8680'\n",
    "    # }\n",
    "    status = verify_aadhaar_record(ocr_extracted)\n",
    "    print(f\"Verification status: {status}\")  # Expected output: 'Yes' or 'No'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09aba4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Using cached psycopg2-2.9.11-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Using cached psycopg2-2.9.11-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7e6127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'kyc_db',\n",
    "    'user': 'postgres',\n",
    "    'password': 'root',\n",
    "    'host': 'localhost',\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "def verify_aadhaar(aadhaar_number, name, dob=None, gender=None):\n",
    "    \"\"\"\n",
    "    Simulates UIDAI authentication - returns Yes/No match\n",
    "    Checks Aadhaar number, full name, date of birth, and gender.\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor(dictionary=True)\n",
    "    \n",
    "    query = \"SELECT * FROM aadhaar_holders WHERE aadhaar_number = %s\"\n",
    "    cursor.execute(query, (aadhaar_number,))\n",
    "    record = cursor.fetchone()\n",
    "    \n",
    "    if not record:\n",
    "        return {\"status\": \"error\", \"code\": \"300\", \"message\": \"Aadhaar number not found\"}\n",
    "    \n",
    "    # Name matching (case-insensitive exact match)\n",
    "    name_match = (record['full_name'].lower().strip() == name.lower().strip())\n",
    "    \n",
    "    # DOB matching (if provided)\n",
    "    dob_match = True\n",
    "    if dob:\n",
    "        dob_match = (str(record['date_of_birth']) == dob)\n",
    "    \n",
    "    # Gender matching (if provided, case-insensitive)\n",
    "    gender_match = True\n",
    "    if gender:\n",
    "        gender_match = (record['gender'].lower().strip() == gender.lower().strip())\n",
    "    \n",
    "    # Overall authentication result\n",
    "    if name_match and dob_match and gender_match:\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"auth_result\": \"Yes\",\n",
    "            \"match_score\": 100,\n",
    "            \"message\": \"Authentication successful\"\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"auth_result\": \"No\",\n",
    "            \"match_score\": 0,\n",
    "            \"message\": \"Authentication failed - details do not match\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d05415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Using cached psycopg2-2.9.11-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Using cached psycopg2-2.9.11-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e483cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# from PIL import Image\n",
    "# from surya.foundation import FoundationPredictor\n",
    "# from surya.recognition import RecognitionPredictor\n",
    "# from surya.detection import DetectionPredictor\n",
    "\n",
    "# # --------------------------\n",
    "# # Load Surya OCR\n",
    "# # --------------------------\n",
    "# image_path = \"aadhaar_sample.jpg\"\n",
    "# image = Image.open(image_path)\n",
    "\n",
    "# foundation_predictor = FoundationPredictor()\n",
    "# recognition_predictor = RecognitionPredictor(foundation_predictor)\n",
    "# detection_predictor = DetectionPredictor()\n",
    "\n",
    "# predictions = recognition_predictor([image], det_predictor=detection_predictor)\n",
    "\n",
    "# --------------------------\n",
    "# Extract text from predictions\n",
    "# --------------------------\n",
    "ocr_text = \" \".join([pred.text for pred in predictions[0]])\n",
    "print(\"\\n--- OCR Output ---\\n\", ocr_text)\n",
    "\n",
    "# --------------------------\n",
    "# Run NER\n",
    "# --------------------------\n",
    "ner = pipeline(\"ner\", model=\"Davlan/xlm-roberta-base-ner-hrl\", grouped_entities=True)\n",
    "entities = ner(ocr_text)\n",
    "\n",
    "print(\"\\n--- Extracted Entities ---\")\n",
    "for ent in entities:\n",
    "    print(f\"{ent['entity_group']}: {ent['word']} (score: {ent['score']:.2f})\")\n",
    "\n",
    "# --------------------------\n",
    "# Map to Aadhaar fields\n",
    "# --------------------------\n",
    "aadhaar_data = {\n",
    "    \"name\": None,\n",
    "    \"dob\": None,\n",
    "    \"aadhaar_number\": None,\n",
    "    \"gender\": None\n",
    "}\n",
    "\n",
    "for ent in entities:\n",
    "    if ent[\"entity_group\"] in [\"PER\"]:\n",
    "        aadhaar_data[\"name\"] = ent[\"word\"]\n",
    "    elif ent[\"entity_group\"] in [\"DATE\"]:\n",
    "        aadhaar_data[\"dob\"] = ent[\"word\"]\n",
    "    elif ent[\"entity_group\"] in [\"ORG\"]:\n",
    "        pass  # government issuer, skip for now\n",
    "\n",
    "# Aadhaar number: 12-digit pattern, not NER\n",
    "import re\n",
    "aadhaar_match = re.search(r\"\\b\\d{4}\\s\\d{4}\\s\\d{4}\\b\", ocr_text)\n",
    "if aadhaar_match:\n",
    "    aadhaar_data[\"aadhaar_number\"] = aadhaar_match.group()\n",
    "\n",
    "# Gender heuristic\n",
    "if \"male\" in ocr_text.lower():\n",
    "    aadhaar_data[\"gender\"] = \"Male\"\n",
    "elif \"female\" in ocr_text.lower():\n",
    "    aadhaar_data[\"gender\"] = \"Female\"\n",
    "\n",
    "print(\"\\n--- Structured Aadhaar Data ---\")\n",
    "print(aadhaar_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
